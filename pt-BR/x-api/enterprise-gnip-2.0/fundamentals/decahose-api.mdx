---
title: API Decahose
---

<Note>
  Este endpoint foi atualizado para incluir metadados de edição de posts. Saiba mais sobre esses metadados na página de fundamentos ["Editar posts"](/pt-BR/x-api/enterprise-gnip-2.0/fundamentals/edit-tweets). 
</Note>

<div id="decahose-stream">
  ### Fluxo Decahose
</div>

[Enterprise](https://developer.x.com/en/products/x-api/enterprise)

_Esta é uma API Enterprise disponível apenas nos nossos níveis de acesso gerenciados. Para usar esta API, você precisa primeiro configurar uma conta com nossa equipe de vendas Enterprise. [Saiba mais](https://developer.x.com/en/products/x-api/enterprise)_

O Decahose fornece uma amostra aleatória de 10% do Firehose do X em tempo real por meio de uma conexão de streaming. Isso é feito por um algoritmo de amostragem em tempo real que seleciona os dados aleatoriamente, ao mesmo tempo que mantém a entrega de baixa latência conforme os dados são enviados pelo firehose do X.

Abaixo estão alguns dos recursos disponíveis no Decahose:

- **URLs expandidas e aprimoradas:** - desfaz completamente URLs encurtadas e fornece metadados adicionais (título e descrição da página)
- **Particionamento do fluxo** - 2 partições, cada uma contendo 50% do volume do fluxo Decahose
- **Confiabilidade aprimorada** - diversidade geográfica dos sistemas de backend

Observação: Esses dados são entregues em lote e não oferecem suporte a filtragem adicional (por exemplo, por palavras-chave).

`ENTERPRISE`

<div id="streaming-likes">
  ### Transmissão de likes
</div>

_Esta é uma API para empresas, disponível apenas nos nossos níveis de acesso gerenciados. Para usar esta API, você deve primeiro configurar uma conta com nossa equipe de vendas para empresas. [Saiba mais](https://developer.x.com/en/products/x-api/enterprise)_

Os likes permitem entender quem curte os Posts e fornecem contagens precisas de curtidas. O Firehose e o Decahose da Gnip podem entregar likes públicos relacionados aos Posts fornecidos via Gnip. Isso gera métricas de engajamento público e de audiência em tempo real associadas a um Post.
 

**Introdução aos likes**

Ao se preparar para consumir dados de likes, você deve saber que:

- Os likes são entregues por um fluxo independente e separado
- Likes eram historicamente chamados de “Favorites”. O payload no formato nativo enriquecido mantém essa nomenclatura
- Os fluxos incluem apenas likes públicos
  - Público significa que o usuário que curtiu, o criador do Post e o próprio Post são todos públicos na plataforma
- Likes são muito semelhantes a Retweets e representam um sinal público de engajamento
- Os elementos do payload incluem:
  - Objeto do Post original
  - Objeto do ator que criou o Post original
  - Objeto do ator que realizou a ação de like
- Apenas conteúdo original pode receber like
  - Retweets não podem receber like. Um like em um Retweet é aplicado ao Post original
  - Tweets com citação _podem_ receber like
- As atividades de like incluem os Gnip Enrichments aplicáveis (quando adquiridos/aplicados)
- Produtos/recursos compatíveis
  - Os fluxos de likes oferecem suporte a Backfill (quando adquirido/aplicado)
  - Não há suporte a Replay para fluxos de likes
  - Não há suporte a Search ou Historical para likes
  - Não há planos imediatos de adicionar suporte a likes no PowerTrack

**Decahose**

- Para os 10% de Posts amostrados entregues no Decahose, o fluxo inclui 100% dos likes públicos aplicáveis
- **Partições:** 2
- **Estrutura de URL**
  - https://gnip-stream.x.com/stream/sample10-likes/accounts/\<accountName>/publishers/twitter/\<streamLabel>.json?partition=1

**Payload no formato nativo enriquecido**

```json
{
   "id":"43560406e0ad9f68374445f5f30c33fc",
   "created_at":"Thu Dec 01 22:27:39 +0000 2016",
   "timestamp_ms":1480631259353,
   "favorited_status":{
      "created_at":"Thu Dec 01 22:27:16 +0000 2016",
      "id":804451830033948672,
      "id_str":"804451830033948672",
      "text":"@kafammheppduman",
      "source":"\u003ca href=\"http:\/\/x.com\/download\/android\" rel=\"nofollow\"\u003eX para Android\u003c\/a\u003e"
      "truncated":false,
      "in_reply_to_status_id":803694205163814912,
      "in_reply_to_status_id_str":"803694205163814912",
      "in_reply_to_user_id":2855759795,
      "in_reply_to_user_id_str":"2855759795",
      "in_reply_to_screen_name":"kafammheppduman",
      "user":{
         "id":2855759795,
         "id_str":"2855759795",
         "name":"delirdim kanka",
         "screen_name":"kafammheppduman",
         "location":"sanane",
         "url":"http:\/\/instagram.com\/kafammheppduman",
         "description":"Manit @GalatasaraySk \ud83d\udc9e",
         "translator_type":"none",
         "protected":false,
         "verified":false,
         "followers_count":3702,
         "friends_count":607,
         "listed_count":1,
         "favourites_count":113338,
         "statuses_count":389,
         "created_at":"Sat Nov 01 22:38:25 +0000 2014",
         "utc_offset":null,
         "time_zone":null,
         "geo_enabled":true,
         "lang":"tr",
         "contributors_enabled":false,
         "is_translator":false,
         "profile_background_color":"C0DEED",
         "profile_background_image_url":"",
         "profile_background_image_url_https":"",
         "profile_background_tile":false,
         "profile_link_color":"1DA1F2",
         "profile_sidebar_border_color":"C0DEED",
         "profile_sidebar_fill_color":"DDEEF6",
         "profile_text_color":"333333",
         "profile_use_background_image":true,
       "Profile_image_url": "http:\/\/pbs.twimg.com\/profile_images\/804421763945861121\/v3bp9pnq_normal.jpg",
         "Profile_image_url_https": "https:\/\/pbs.twimg.com\/profile_images\/804421763945861121\/v3bp9pnq_normal.jpg",
         "profile_banner_url":"https:\/\/pbs.twimg.com\/profile_banners\/2855759795\/1480630085",
         "default_profile":true,
         "default_profile_image":false,
         "following":null,
         "follow_request_sent":null,
         "notifications":null
      },
      "geo":null,
      "coordinates":null,
      "place":null,
      "contributors":null,
      "is_quote_status":false,
      "retweet_count":0,
      "favorite_count":0,
      "entities":{
         "hashtags":[],
         "urls":[],
         "user_mentions":[
            {
               "screen_name":"kafammheppduman",
               "name":"delirdim kanka",
               "id":2855759795,
               "id_str":"2855759795",
               "indices":[
                  0,
                  16
               ]
            }
         ],
         "symbols":[]
      },
      "favorited":false,
      "retweeted":false,
      "filter_level":"low",
      "lang":"und"
   },
   "user":{
      "id":774146932365070336,
      "id_str":"774146932365070336",
      "name":"Uyuyan Adam",
      "screen_name":"saykoMenn",
      "location":"Tarsus, T\u00fcrkiye",
      "url":"http:\/\/connected2.me\/pmc1i",
      "description":null,
      "translator_type":"none",
      "protected":false,
      "verified":false,
      "followers_count":414,
      "friends_count":393,
      "listed_count":0,
      "favourites_count":9868,
      "statuses_count":370,
      "created_at":"Fri Sep 09 07:26:26 +0000 2016",
      "utc_offset":null,
      "time_zone":null,
      "geo_enabled":false,
      "lang":"tr",
      "contributors_enabled": false,
      "is_translator": false,
      "profile_background_color": "F5F8FA",
      "profile_background_image_url": "",
      "profile_background_image_url_https": "",
      "profile_background_tile": false,
      "profile_link_color": "1DA1F2",
      "profile_sidebar_border_color": "C0DEED",
      "profile_sidebar_fill_color": "DDEEF6",
      "profile_text_color": "333333",
      "profile_use_background_image": true,
      "profile_image_url": "http:\/\/pbs.twimg.com\/profile_images\/802992813424201728\/VMzcTL3x_normal.jpg",
      "profile_image_url_https": "https:\/\/pbs.twimg.com\/profile_images\/802992813424201728\/VMzcTL3x_normal.jpg",
      "profile_banner_url": "https:\/\/pbs.twimg.com\/profile_banners\/774146932365070336\/1480283382",
      "default_profile": true,
      "default_profile_image": false,
      "following": null,
      "follow_request_sent": null,
      "notifications": null
   }
}
```

**Payload de exclusão de curtida / “Descurtir”**

```json
{
   "delete":{
      "favorite":{
         "tweet_id":696615514970279937,
         "tweet_id_str":"696615514970279937",
         "user_id":2510287578,
         "user_id_str":"2510287578"
      },
      "timestamp_ms":"1480437031205"
   }
}
```

<div id="guides">
  ## Guias
</div>

<div id="recovery-and-redundency">
  ### Recuperação e Redundância
</div>

**Introdução** 

Com o streaming de grandes volumes de Posts em tempo real, há um conjunto de boas práticas que promovem tanto a confiabilidade quanto a fidelidade integral dos dados. Ao consumir dados em tempo real, maximizar o tempo de conexão é um objetivo fundamental. Quando ocorrerem desconexões, é importante detectá-las automaticamente e reconectar. Após reconectar, é importante avaliar se há períodos a serem preenchidos com backfill de dados. O componente que gerencia esses detalhes e consome Posts em tempo real é apenas uma parte de um sistema com demandas de rede, datastore, servidor e armazenamento. Dada a complexidade desses sistemas, outra boa prática é manter diferentes ambientes de streaming, com pelo menos fluxos separados para desenvolvimento/testes e produção.

O Decahose oferece um conjunto de recursos que ajudam nesses esforços.

1. Para dar suporte a múltiplos ambientes, podemos implantar [Additional Streams](#AdditionalStreams) para sua conta. Esses fluxos são independentes entre si e têm um stream\_label diferente para ajudar a diferenciá-los.
2. Para ajudar a manter a conexão, cada fluxo do Decahose dá suporte a [Redundant Connections](/pt-BR/x-api/enterprise-gnip-2.0/fundamentals/decahose-api#additional-streams). A arquitetura mais comum é um fluxo ter duas conexões e, no lado do cliente, haver dois consumidores independentes — idealmente em redes diferentes. Com esse desenho, pode haver redundância entre as redes do lado do cliente, servidores e caminhos do datastore. Observe que uma cópia completa dos dados é entregue em cada conexão e o lado do cliente deve tolerar e gerenciar dados duplicados.
3. Um “heartbeat” será enviado a cada 10 segundos; no entanto, com o fluxo do Decahose, o volume de dados é alto o suficiente para que mesmo uma pequena duração (por exemplo, alguns segundos) sem Posts possa indicar um problema de conexão. Portanto, tanto um “silêncio de dados” quanto a ausência de um heartbeat podem ser usados para detectar uma desconexão.

Como desconexões acontecerão, o fluxo do Decahose possui recursos dedicados de [Recovery](/pt-BR/x-api/enterprise-gnip-2.0/fundamentals/decahose-api#overview) e [Backfill](/pt-BR/x-api/enterprise-gnip-2.0/fundamentals/decahose-api#backfill) para ajudar a recuperar dados perdidos devido a desconexões e outros problemas operacionais.

<div id="additional-streams">
  #### Streams adicionais
</div>

Ter streams Decahose adicionais é outra forma de aumentar a confiabilidade da sua solução. Quaisquer streams adicionais são completamente independentes, com seu próprio endpoint. Cada stream recebe seu próprio stream\_label e esse rótulo, juntamente com o nome da sua conta, fazem parte da URL desse stream. Veja o exemplo abaixo:

https://gnip-stream.x.com/stream/sample10/accounts/:account\_name/publishers/twitter/:stream\_label.json

A convenção mais comum é ter um stream em tempo real dedicado ao seu sistema de produção e um stream adicional disponível para desenvolvimento e testes. Ter um stream de teste/desenvolvimento permite que clientes do Decahose testem atualizações dos consumidores (clients). Embora qualquer rótulo (único) possa ser atribuído a um stream, uma convenção é usar “prod” para o stream de produção e “dev” ou “sandbox” para um stream de desenvolvimento adicional.

O número de streams e seus rótulos exclusivos é configurável pelo representante da sua conta.

**Conexões redundantes**

Uma conexão redundante simplesmente permite estabelecer mais de uma conexão simultânea ao stream de dados. Isso oferece redundância ao permitir que você se conecte ao mesmo stream com dois consumidores separados, recebendo os mesmos dados por ambas as conexões. Assim, seu app tem um hot failover para várias situações, por exemplo, quando um stream é desconectado ou quando o servidor primário do seu app falha.

O número de conexões permitido para qualquer stream é configurável pelo representante da sua conta. Para usar um stream redundante, conecte-se à mesma URL usada para sua conexão principal. Os dados do seu stream serão enviados por ambas as conexões, com ambas as conexões representadas no painel do stream.

Observe que, para fins de cobrança, deduplicamos as contagens de atividades recebidas por múltiplas conexões, de modo que você seja cobrado apenas uma vez por cada atividade exclusiva. Como o Decahose tem duas partições, segue um exemplo de como funciona a contagem de conexões:

Connect to decahose partition=1
Connect to decahose partition=1
Connect to decahose partition=2

A situação acima resulta em um total de três conexões — duas conexões para partition=1 e uma conexão para partition=2. Normalmente, você desejaria o mesmo número de conexões para cada partição; portanto, este exemplo destaca uma situação em que a conexão redundante para partition=2 caiu e você deve investigar.

**Recuperação**

#### Visão geral 

Recovery é uma ferramenta de recuperação de dados (não deve ser usada para coleta primária) que oferece acesso em streaming a uma janela móvel de 5 dias de dados históricos recentes do X. Ela deve ser utilizada para recuperar dados quando seu aplicativo consumidor perder informações no fluxo em tempo real, seja por uma desconexão breve ou por qualquer outro motivo que o impeça de ingerir dados em tempo real por um período.

#### Usando o Recovery 

Com o fluxo Recovery, seu app pode fazer solicitações que funcionam da mesma forma que as solicitações aos fluxos em tempo real. No entanto, seu app deve especificar parâmetros na URL que indiquem a janela de tempo desejada. Em outras palavras, uma solicitação de Recovery pede à API: "Posts do horário A ao horário B". Esses posts são então entregues pela sua conexão de streaming de modo a imitar o fluxo em tempo real, mas a uma taxa ligeiramente inferior à de tempo real. Veja abaixo um exemplo:

"https://stream-data-api.x.com/stream/powertrack/accounts/someAccountName/publishers/twitter/powertrack.json?startTime=2023-07-05T17:09:12.070Z"

Os posts são entregues começando pelo primeiro (mais antigo) minuto do período especificado, seguindo cronologicamente até que o último minuto seja entregue. Nesse ponto, uma mensagem Recovery Request Completed é enviada pela conexão e, em seguida, o servidor a encerra. Se sua solicitação começar em um horário do dia em que poucos ou nenhum resultado correspondente tenha ocorrido, provavelmente haverá um intervalo antes da entrega dos primeiros resultados — os dados serão enviados quando o Recovery encontrar correspondências na parte do arquivo que estiver sendo processada naquele momento. Quando não houver resultados para entregar, o fluxo continuará enviando caracteres de retorno de carro, ou “batimentos” (“heartbeats”), pela conexão para evitar tempo limite.

O Recovery é uma ferramenta destinada a recuperar facilmente dados perdidos devido a desconexões curtas, e não para períodos muito longos, como um dia inteiro. Se houver necessidade de recuperar dados por longos períodos, recomendamos dividir solicitações maiores em janelas menores (por exemplo, de duas horas) para reduzir a possibilidade de desconexão no meio da solicitação devido à volatilidade da internet ou outros motivos, além de fornecer mais visibilidade sobre o andamento de solicitações longas.

<div id="data-availability">
  #### Disponibilidade de dados
</div>

Você pode usar o recurso de Recuperação para recuperar dados perdidos nas últimas 24 horas se não conseguir se reconectar dentro da janela de preenchimento retroativo de 5 minutos.

O recurso de recuperação de streaming permite uma janela estendida de preenchimento retroativo de 24 horas. A Recuperação permite “recuperar” o período de dados perdidos. Um fluxo de recuperação é iniciado quando você faz uma solicitação de conexão usando os parâmetros de solicitação 'start\_time' e 'end\_time'. Depois de conectado, a Recuperação retransmitirá o período indicado e, em seguida, desconectará.

Você poderá fazer 2 solicitações simultâneas de recuperação, ou seja, “dois jobs de recuperação”. A Recuperação funciona tecnicamente da mesma forma que o preenchimento retroativo, exceto pelo fato de que um horário de início e um de término são definidos. Um período de recuperação contempla um único intervalo de tempo.

<div id="backfill">
  #### Backfill
</div>

Para solicitar backfill, você precisa adicionar o parâmetro backfillMinutes=N à sua solicitação de conexão, em que N é o número de minutos (1–5, apenas inteiros) a serem recuperados quando a conexão for estabelecida. Por exemplo, se você se desconectar por 90 segundos, deve adicionar backfillMinutes=2 à solicitação de conexão. Como essa solicitação retornará backfill por 2 minutos, incluindo os 30 segundos anteriores à desconexão, seu _app consumidor deve tolerar dados duplicados_.

Um exemplo de URL de solicitação de conexão do Decahose, solicitando backfill de 5 minutos para a partição 1, é:

https://gnip-stream.x.com/stream/sample10/accounts/:account\_name/publishers/twitter/:stream\_label.json?partition=1\&backfillMinutes=5

**NOTAS:**

- Você pode optar por sempre usar ‘backfillMinutes=5’ ao se conectar e, então, lidar com quaisquer dados duplicados retornados.

- Se você ficar desconectado por mais de cinco minutos, é possível recuperar os dados usando Recovery.

**Recuperando de uma desconexão**

Reiniciar e recuperar de uma desconexão envolve várias etapas:

- Determinar a duração do período de desconexão.
  - 5 minutos ou menos?
    - Se você tiver Backfill habilitado para o stream, prepare a solicitação de conexão com o parâmetro ‘backfillMinutes’ apropriado.
  - Mais de 5 minutos?
    - Se você tiver um stream de Recovery, faça uma solicitação de Recovery para o período desconectado (de preferência com seu conjunto de regras de tempo real atual, usando a Rules API se necessário).
- Solicitar uma nova conexão.

Quando você enfrentar desconexões ou indisponibilidade, aqui estão estratégias para mitigar e se recuperar nesse cenário:

1. **Implemente backfill**
   O backfill permite reconectar a partir de um ponto anterior à desconexão de um stream e cobre interrupções de até 5 minutos. É implementado incluindo um parâmetro na solicitação de conexão.

2. **Consuma um stream redundante de outra localização**
   Se o stream redundante puder ser direcionado para o mesmo ambiente de produção, com desduplicação de dados, você eliminará a necessidade de recuperação, a menos que AMBOS o stream principal e o redundante tenham indisponibilidade ou desconexões simultâneas. Se o stream redundante não puder ser transmitido ao vivo para o ambiente de produção, ele pode ser gravado em um repositório de dados “de emergência” separado. Assim, no caso de desconexões ou indisponibilidade na conexão do stream principal, seu sistema terá dados à mão para preencher o banco de dados primário no período em que houver lacunas de dados.

3. **Implemente Recovery**
   Quando a indisponibilidade afetar tanto o stream principal quanto o redundante, use o Decahose Recovery para recuperar quaisquer dados perdidos. A API fornece uma janela contínua cobrindo 5 dias do arquivo e é melhor utilizada solicitando no máximo uma hora dessa janela por vez e transmitindo-a. Isso é feito em paralelo ao stream em tempo real. Observe que não há soluções para recuperar dados do Decahose além da janela de 5 dias fornecida por Recovery; portanto, é importante utilizar um stream redundante para garantir uma cópia completa dos dados do seu lado em caso de indisponibilidade significativa.

Quando você detectar volumes anormais de dados armazenados —
Maneiras de identificar dados ausentes quando não ocorreram desconexões ou indisponibilidade…

1. Conte os Posts recebidos
   Seu sistema deve contar o número bruto de Posts recebidos logo no início do seu app de ingestão e, depois, fornecer uma forma de comparar esses números com a quantidade de Posts que chega ao repositório de dados final. Quaisquer diferenças podem ser monitoradas e servir de alerta à sua equipe sobre problemas que causem perda de dados após o recebimento.

2. Analise volumes armazenados anormais
   Você também pode analisar os volumes de dados armazenados no banco de dados final para identificar quedas anormais. Isso pode indicar problemas, embora existam circunstâncias em que quedas de volume sejam normais (por exemplo, se a plataforma X estiver indisponível e as pessoas não puderem criar Posts por algum período).

<div id="api-reference">
  ## Referência da API
</div>

<div id="decahose-stream">
  ### Fluxo Decahose
</div>

Ir para nesta página

[Métodos](/pt-BR/x-api/enterprise-gnip-2.0/fundamentals/decahose-api#methods)

[Autenticação](/pt-BR/x-api/enterprise-gnip-2.0/fundamentals/decahose-api#authentication)

[GET /\{stream-type}/:stream](/pt-BR/x-api/enterprise-gnip-2.0/fundamentals/decahose-api#get-stream-type-stream)

[API de Replay](/pt-BR/x-api/enterprise-gnip-2.0/fundamentals/decahose-api#replay-api)

<div id="methods">
  #### Métodos
</div>

| Método | Descrição |
| :--- | :--- |
| [GET /\{stream-type}/:stream](#Stream) | Conectar ao fluxo de dados |

<div id="authentication">
  #### Autenticação[](#authentication- "Permalink to this headline")
</div>

Todas as solicitações às APIs de Volume Stream devem usar autenticação básica HTTP, composta por um endereço de e-mail e senha válidos usados para fazer login na sua conta em console.gnip.com. As credenciais devem ser enviadas no cabeçalho Authorization de cada solicitação. Portanto, confirme que seu cliente está adicionando o cabeçalho HTTP "Authorization: Basic" (com as credenciais codificadas via HTTPS) a todas as solicitações da API.

#### GET \{stream-type}:stream

Estabelece uma conexão persistente com o fluxo Firehose, por meio da qual os dados em tempo real serão fornecidos.

<div id="request-specifications">
  #### Especificações da solicitação
</div>

|     |     |
| :--- | :--- |
| **Método da solicitação** | HTTP GET |
| **Tipo de conexão** | Keep-Alive  <br />  <br />Isso deve ser especificado no cabeçalho da solicitação. |
| **URL** | Disponível na página de Ajuda da API do fluxo no seu painel, seguindo a estrutura:  <br />  <br />Decahose:<br /><br />[https://gnip-stream.x.com/stream/sample10/accounts/:account\_name/publishers/twitter/:stream\_label.json?partition=1](https://gnip-stream.x.com/stream/sample10/accounts/:account_name/publishers/twitter/:stream_label.json?partition=1) |
| **Partição (obrigatória)** | `partition=\{#}` - A partição agora é obrigatória para consumir o fluxo completo. Você precisará se conectar ao fluxo com o parâmetro de partição especificado. Abaixo está o número de partições por fluxo:<br /><br />\* Decahose: 2 partições |
| **Compactação** | Gzip. Para se conectar ao fluxo usando compactação Gzip, basta enviar um cabeçalho Accept-Encoding na solicitação de conexão. O cabeçalho deve ser:  <br />  <br />Accept-Encoding: gzip |
| **Codificação de caracteres** | UTF-8 |
| **Formato da resposta** | JSON. O cabeçalho da sua solicitação deve especificar o formato JSON para a resposta. |
| **Limite de taxa** | 10 solicitações a cada 60 segundos. |
| **Parâmetro de Backfill** | Se você adquiriu um fluxo com Backfill ativado, será necessário adicionar o parâmetro "backfillMinutes" na solicitação GET para habilitá-lo. |
| **Tempo limite de leitura** | Defina um tempo limite de leitura no seu cliente e garanta que esteja configurado para um valor acima de 30 segundos. |
| **Suporte a edições de Tweets** | Todos os objetos de Tweet incluirão metadados de edição descrevendo o histórico de edições do Tweet. Consulte a página de fundamentos ["Editar Tweets"](/pt-BR/x-api/enterprise-gnip-2.0/fundamentals/edit-tweets) para mais detalhes. |

<div id="responses">
  #### Respostas
</div>

As seguintes respostas podem ser retornadas pela API para essas solicitações. A maioria dos códigos de erro é retornada com uma string contendo detalhes adicionais no corpo. Para respostas diferentes de 200, os clientes devem tentar restabelecer a conexão.

| Status | Texto | Descrição |
| :--- | :--- | :--- |
| 200 | Sucesso | A conexão foi aberta com êxito e novas atividades serão enviadas conforme chegarem. |
| 401 | Não autorizado | A autenticação HTTP falhou devido a credenciais inválidas. Faça login em console.gnip.com com suas credenciais para garantir que está usando-as corretamente na sua solicitação. |
| 406 | Não aceitável | Geralmente ocorre quando o cliente não inclui corretamente os cabeçalhos para aceitar a codificação gzip do fluxo, mas também pode ocorrer em outras circunstâncias.  <br />  <br />Conterá uma mensagem JSON semelhante a "Esta conexão requer compactação. Para habilitar a compactação, envie um cabeçalho 'Accept-Encoding: gzip' na sua solicitação e esteja preparado para descompactar o fluxo conforme ele é lido no lado do cliente." |
| 429 | Limite de taxa excedido | Seu app excedeu o limite de solicitações de conexão. |
| 503 | Serviço indisponível | Problema no servidor do X. Reconecte usando uma estratégia de espera exponencial (exponential backoff). Se nenhum aviso sobre esse problema tiver sido publicado na [Página de Status da API do X](https://api.twitterstat.us/), entre em contato com o suporte ou com a central de emergências se não conseguir se conectar após 10 minutos. |

<div id="example-curl-request">
  #### Exemplo de solicitação com curl
</div>

O exemplo a seguir usa cURL na linha de comando. No entanto, observe que essas solicitações também podem ser enviadas na linguagem de programação de sua preferência:

```
curl --compressed -v -uexample@customer.com "https://gnip-stream.x.com/stream/firehose/accounts/:account\_name/publishers/twitter/:stream\_label.json?partition={#}"
```

<div id="replay-api">
  #### API de Replay
</div>

A API de Replay é um complemento importante aos fluxos de Volume em tempo real. O Replay é uma ferramenta de recuperação de dados que fornece acesso por streaming a uma janela contínua dos dados históricos recentes do X.