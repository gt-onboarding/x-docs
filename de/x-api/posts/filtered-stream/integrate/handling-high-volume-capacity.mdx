---
title: Umgang mit hohem Volumen
sidebarTitle: Umgang mit hohem Volumen
---

<div id="how-to-plan-for-high-volume-social-data-events">
  ### So planen Sie für Social-Data-Ereignisse mit hohem Datenaufkommen
</div>

Große nationale und globale Ereignisse gehen oft mit deutlichen Spitzen der Nutzeraktivität auf Social-Media-Plattformen einher. Manche dieser Ereignisse sind im Voraus bekannt, etwa der Super Bowl, politische Wahlen oder weltweite Neujahrsfeiern. Andere Volumenspitzen entstehen durch unvorhergesehene Ereignisse wie Naturkatastrophen, ungeplante politische Entwicklungen, Popkulturmomente oder Gesundheitskrisen wie COVID‑19.

Diese Spitzen der Nutzeraktivität können sehr kurz sein (in Sekunden gemessen) oder sich über mehrere Minuten erstrecken. Unabhängig von ihrer Ursache ist es wichtig, die Auswirkungen auf Anwendungen zu berücksichtigen, die Daten von X verarbeiten. Im Folgenden finden Sie einige Best Practices, die Ihrem Team helfen, sich auf Social-Data-Ereignisse mit hohem Datenaufkommen vorzubereiten.

<div id="review-your-current-filtered-stream-rules">
  #### Überprüfen Sie Ihre aktuellen Regeln für den Gefilterten Stream
</div>

* Bestimmte Keywords können bei Ereignissen mit hohem Aufkommen sprunghaft ansteigen, etwa Markennennungen, wenn eine Marke ein großes Sportereignis sponsert.
* Achten Sie darauf, unnötige oder zu allgemein gehaltene Regeln zu vermeiden, die überflüssige Aktivität erzeugen könnten.
* Erwägen Sie, vor absehbaren Ereignissen mit hohem Aufkommen mit Ihren Kundinnen und Kunden zu sprechen, um eine angemessene Planung zu ermöglichen.
     

<div id="stress-test-your-application">
  #### Stresstest Ihrer Anwendung
</div>

Rechnen Sie damit, dass Spitzenvolumina das 5- bis 10-Fache des durchschnittlichen täglichen Verbrauchs erreichen können. Je nach Regelsatz kann der Anstieg deutlich höher ausfallen.

<div id="understand-delivery-caps-for-connections">
  #### Zustelllimits für Verbindungen verstehen
</div>

Flow- und Zustelllimits basieren auf Zugriffsebenen. Dies führt zu einem festen Volumen ausgelieferter Ergebnisse für Streams.

* **Academic**: 250 Posts/Sekunde
* **Enterprise**: Posts/Sekunde wird durch die Zugriffsebene festgelegt

<div id="optimize-to-stay-connected">
  #### Optimieren, um verbunden zu bleiben
</div>

Bei Streams ist es entscheidend, verbunden zu bleiben, um keine Daten zu verlieren. Ihre Client-Anwendung sollte Verbindungsabbrüche erkennen und eine Logik besitzen, die die Verbindung sofort erneut herstellt; schlägt der erneute Verbindungsversuch fehl, sollte ein exponentielles Backoff genutzt werden.
 

<div id="add-built-in-buffering-on-your-end">
  #### Pufferung auf Ihrer Seite einbauen
</div>

Der Aufbau einer Multithread-Anwendung ist eine zentrale Strategie für die Verarbeitung hochvolumiger Streams. Auf hoher Ebene gilt als Best Practice für das Management von Datenströmen, einen separaten Thread/Prozess zu verwenden, der die Streaming-Verbindung herstellt und empfangene JSON-Aktivitäten in eine Speicherstruktur oder einen gepufferten Stream-Reader schreibt. Dieser „leichtgewichtige“ Stream-Verarbeitungs-Thread ist dafür verantwortlich, eingehende Daten zu behandeln, die im Speicher gepuffert werden können und sich nach Bedarf vergrößern oder verkleinern. Anschließend konsumiert ein anderer Thread diesen Puffer und übernimmt die „schwere Arbeit“: das Parsen des JSON, die Vorbereitung von Datenbankschreibvorgängen oder was auch immer Ihre Anwendung sonst ausführen muss.
 

<div id="global-events-global-time-zones">
  #### Globale Ereignisse = globale Zeitzonen
</div>

Ereignisse können außerhalb der Geschäftszeiten oder am Wochenende auftreten. Stellen Sie daher sicher, dass Ihr Team auf Spitzen außerhalb der üblichen Geschäftszeiten vorbereitet ist.