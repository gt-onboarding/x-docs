---
title: Decahose-API
---

<Note>
  Dieser Endpunkt wurde aktualisiert und enthält nun Metadaten zu Post-Bearbeitungen. Weitere Informationen zu diesen Metadaten finden Sie auf der Grundlagen-Seite „Posts bearbeiten“ ([Edit Posts](/de/x-api/enterprise-gnip-2.0/fundamentals/edit-tweets)).
</Note>

<div id="decahose-stream">
  ### Decahose-Stream
</div>

[Enterprise](https://developer.x.com/en/products/x-api/enterprise)

_Dies ist eine Enterprise-API, die nur in unseren verwalteten Zugriffsstufen verfügbar ist. Um diese API zu nutzen, müssen Sie zunächst ein Konto über unser Enterprise-Vertriebsteam einrichten. [Weitere Informationen](https://developer.x.com/en/products/x-api/enterprise)_

Die Decahose liefert über eine Streaming-Verbindung eine zufällige 10%-Stichprobe des Echtzeit-X-Firehose. Dies geschieht mittels eines Echtzeit-Sampling-Algorithmus, der Daten zufällig auswählt und gleichzeitig die erwartete, latenzarme Zustellung der Daten ermöglicht, während sie von X über die Firehose gesendet werden.

Im Folgenden sind einige der mit Decahose verfügbaren Funktionen aufgeführt:

- **Erweiterte und aufgelöste URLs:** – löst verkürzte URLs vollständig auf und stellt zusätzliche Metadaten bereit (Seitentitel und Beschreibung)
- **Stream-Partitionierung** – 2 Partitionen, jeweils 50 % des Volumens des Decahose-Streams
- **Höhere Zuverlässigkeit** – geografische Diversität der Backend-Systeme

Hinweis: Diese Daten werden in Batches geliefert und unterstützen keine zusätzliche Filterung (z. B. nach Schlüsselwörtern).

`ENTERPRISE`

<div id="streaming-likes">
  ### Streaming-Likes
</div>

_Dies ist eine Enterprise-API, die ausschließlich innerhalb unserer verwalteten Zugriffsstufen verfügbar ist. Um diese API zu nutzen, müssen Sie zunächst ein Konto über unser Enterprise-Sales-Team einrichten. [Mehr erfahren](https://developer.x.com/en/products/x-api/enterprise)_

Likes liefern Einblicke, wer Posts mit „Gefällt mir“ markiert, und stellen genaue Like-Zählungen bereit. Die Firehose und Decahose von Gnip können öffentliche Likes zu den über Gnip gelieferten Posts bereitstellen. Dies ermöglicht Echtzeitmetriken zur öffentlichen Interaktion und zur Zielgruppe, die einem Post zugeordnet sind.
 

**Erste Schritte mit Likes**

Wenn Sie sich auf die Verarbeitung von Likes-Daten vorbereiten, sollten Sie Folgendes wissen:

- Likes werden über einen eigenständigen, separaten Stream geliefert
- Likes wurden historisch als „Favorites“ bezeichnet. Die angereicherte native Formatnutzlast behält diese Nomenklatur bei
- Streams enthalten nur öffentliche Likes
  - Öffentlich bedeutet, dass der likende Nutzer, der Post-Ersteller und der Post auf der Plattform jeweils öffentlich sind
- Likes sind Retweets sehr ähnlich und stellen ein öffentliches Signal für Engagement dar
- Elemente der Nutzlast umfassen:
  - Originales Post-Objekt
  - Actor-Objekt, das den ursprünglichen Post erstellt hat
  - Actor-Objekt, das die Like-Aktion ausgeführt hat
- Nur Originalinhalte können geliked werden
  - Retweets können nicht geliked werden. Ein Like auf einen Retweet wird dem ursprünglichen Post zugerechnet
  - Zitierte Tweets _können_ geliked werden
- Like-Aktivitäten umfassen anwendbare Gnip-Enrichments (falls erworben/angewendet)
- Unterstützte Produkte/Funktionen
  - Likes-Streams unterstützen Backfill (falls erworben/angewendet)
  - Es gibt keine Replay-Unterstützung für Likes-Streams
  - Es gibt keine Search- oder Historical-Unterstützung für Likes
  - Es gibt derzeit keine Pläne, Likes-Unterstützung zu PowerTrack hinzuzufügen

**Decahose**

- Für die 10%-Stichprobe der in der Decahose gelieferten Posts enthält der Stream 100% der entsprechenden öffentlichen Likes
- **Partitionen:** 2
- **URL-Struktur**
  - https://gnip-stream.x.com/stream/sample10-likes/accounts/\<accountName>/publishers/twitter/\<streamLabel>.json?partition=1

**Angereicherte native Formatnutzlast**

```json
{
   "id":"43560406e0ad9f68374445f5f30c33fc",
   "created_at":"Thu Dec 01 22:27:39 +0000 2016",
   "timestamp_ms":1480631259353,
   "favorited_status":{
      "created_at":"Thu Dec 01 22:27:16 +0000 2016",
      "id":804451830033948672,
      "id_str":"804451830033948672",
      "text":"@kafammheppduman",
      "source":"\u003ca href=\"http:\/\/x.com\/download\/android\" rel=\"nofollow\"\u003eX für Android\u003c\/a\u003e"
      "truncated":false,
      "in_reply_to_status_id":803694205163814912,
      "in_reply_to_status_id_str":"803694205163814912",
      "in_reply_to_user_id":2855759795,
      "in_reply_to_user_id_str":"2855759795",
      "in_reply_to_screen_name":"kafammheppduman",
      "user":{
         "id":2855759795,
         "id_str":"2855759795",
         "name":"delirdim kanka",
         "screen_name":"kafammheppduman",
         "location":"sanane",
         "url":"http:\/\/instagram.com\/kafammheppduman",
         "description":"Manit @GalatasaraySk \ud83d\udc9e",
         "translator_type":"none",
         "protected":false,
         "verified":false,
         "followers_count":3702,
         "friends_count":607,
         "listed_count":1,
         "favourites_count":113338,
         "statuses_count":389,
         "created_at":"Sat Nov 01 22:38:25 +0000 2014",
         "utc_offset":null,
         "time_zone":null,
         "geo_enabled":true,
         "lang":"tr",
         "contributors_enabled":false,
         "is_translator":false,
         "profile_background_color":"C0DEED",
         "profile_background_image_url":"",
         "profile_background_image_url_https":"",
         "profile_background_tile":false,
         "profile_link_color":"1DA1F2",
         "profile_sidebar_border_color":"C0DEED",
         "profile_sidebar_fill_color":"DDEEF6",
         "profile_text_color":"333333",
         "profile_use_background_image":true,
       "Profile_image_url": "http:\/\/pbs.twimg.com\/profile_images\/804421763945861121\/v3bp9pnq_normal.jpg",
         "Profile_image_url_https": "https:\/\/pbs.twimg.com\/profile_images\/804421763945861121\/v3bp9pnq_normal.jpg",
         "profile_banner_url":"https:\/\/pbs.twimg.com\/profile_banners\/2855759795\/1480630085",
         "default_profile":true,
         "default_profile_image":false,
         "following":null,
         "follow_request_sent":null,
         "notifications":null
      },
      "geo":null,
      "coordinates":null,
      "place":null,
      "contributors":null,
      "is_quote_status":false,
      "retweet_count":0,
      "favorite_count":0,
      "entities":{
         "hashtags":[],
         "urls":[],
         "user_mentions":[
            {
               "screen_name":"kafammheppduman",
               "name":"delirdim kanka",
               "id":2855759795,
               "id_str":"2855759795",
               "indices":[
                  0,
                  16
               ]
            }
         ],
         "symbols":[]
      },
      "favorited":false,
      "retweeted":false,
      "filter_level":"low"
      "lang":"und"
   },
   "user":{
      "id":774146932365070336,
      "id_str":"774146932365070336",
      "name":"Uyuyan Adam",
      "screen_name":"saykoMenn",
      "location":"Tarsus, T\u00fcrkiye",
      "url":"http:\/\/connected2.me\/pmc1i",
      "description":null,
      "translator_type":"none",
      "protected":false,
      "verified":false,
      "followers_count":414,
      "friends_count":393,
      "listed_count":0,
      "favourites_count":9868,
      "statuses_count":370,
      "created_at":"Fri Sep 09 07:26:26 +0000 2016",
      "utc_offset":null,
      "time_zone":null,
      "geo_enabled":false,
      "lang":"tr",
      "contributors_enabled": false,
      "is_translator": false,
      "profile_background_color": "F5F8FA",
      "profile_background_image_url": "",
      "profile_background_image_url_https": "",
      "profile_background_tile": false,
      "profile_link_color": "1DA1F2",
      "profile_sidebar_border_color": "C0DEED",
      "profile_sidebar_fill_color": "DDEEF6",
      "profile_text_color": "333333",
      "profile_use_background_image": true,
      "profile_image_url": "http:\/\/pbs.twimg.com\/profile_images\/802992813424201728\/VMzcTL3x_normal.jpg",
      "profile_image_url_https": "https:\/\/pbs.twimg.com\/profile_images\/802992813424201728\/VMzcTL3x_normal.jpg",
      "profile_banner_url": "https:\/\/pbs.twimg.com\/profile_banners\/774146932365070336\/1480283382",
      "default_profile": true,
      "default_profile_image": false,
      "following": null,
      "follow_request_sent": null,
      "notifications": null
   }
}
```

**Like entfernen / „Gefällt mir“-Aufhebung-Payload**

```json
{
   "delete":{
      "favorite":{
         "tweet_id":696615514970279937,
         "tweet_id_str":"696615514970279937",
         "user_id":2510287578,
         "user_id_str":"2510287578"
      },
      "timestamp_ms":"1480437031205"
   }
}
```

<div id="guides">
  ## Anleitungen
</div>

<div id="recovery-and-redundency">
  ### Wiederherstellung und Redundanz
</div>

**Einführung** 

Beim Streamen großer Mengen von Echtzeit-Posts gibt es eine Reihe von Best Practices, die sowohl die Datenzuverlässigkeit als auch die vollständige Datenintegrität fördern. Beim Konsumieren von Echtzeitdaten ist die Maximierung der Verbindungszeit ein grundlegendes Ziel. Wenn Verbindungsabbrüche auftreten, ist es wichtig, diese automatisch zu erkennen und die Verbindung wiederherzustellen. Nach dem Wiederverbinden sollte geprüft werden, ob es Zeiträume gibt, für die Daten nachträglich ergänzt werden müssen. Die Komponente, die diese Details verwaltet und Echtzeit-Posts verarbeitet, ist nur ein Teil eines Systems mit Anforderungen an Netzwerk, Datenbank, Server und Storage. Angesichts der Komplexität dieser Systeme ist eine weitere Best Practice, unterschiedliche Streaming-Umgebungen zu betreiben, mit mindestens getrennten Streams für Entwicklung/Tests und Produktion.

Decahose bietet eine Reihe von Funktionen, die diese Maßnahmen unterstützen.

1. Zur Unterstützung mehrerer Umgebungen können wir [Additional Streams](#AdditionalStreams) für Ihr Konto bereitstellen. Diese Streams sind unabhängig voneinander und haben ein anderes stream\_label, um sie zu unterscheiden.
2. Zur Stabilisierung der Verbindung unterstützt jeder Decahose-Stream [Redundant Connections](/de/x-api/enterprise-gnip-2.0/fundamentals/decahose-api#additional-streams). Die gängigste Architektur sieht vor, dass ein Stream zwei Verbindungen hat und clientseitig zwei unabhängige Consumer laufen – idealerweise in unterschiedlichen Netzwerken. Mit diesem Design entsteht Redundanz über die clientseitigen Netzwerke, Server und Datenpfade hinweg. Beachten Sie, dass über jede Verbindung eine vollständige Kopie der Daten geliefert wird und die Client-Seite Duplikate tolerieren und handhaben muss.
3. Alle 10 Sekunden wird ein „Heartbeat“ gesendet; beim Decahose-Stream ist das Datenvolumen jedoch so hoch, dass bereits eine kurze Phase (z. B. einige Sekunden) ohne Posts auf ein Verbindungsproblem hinweisen kann. Daher können sowohl eine „Datensilence“ als auch das Ausbleiben eines Heartbeats verwendet werden, um einen Verbindungsabbruch zu erkennen.

Da Verbindungsabbrüche auftreten werden, verfügt der Decahose-Stream über eine dedizierte [Recovery](/de/x-api/enterprise-gnip-2.0/fundamentals/decahose-api#overview)- und eine [Backfill](/de/x-api/enterprise-gnip-2.0/fundamentals/decahose-api#backfill)-Funktion, um Daten wiederherzustellen, die aufgrund von Verbindungsabbrüchen und anderen betrieblichen Problemen verpasst wurden.

<div id="additional-streams">
  #### Zusätzliche Streams
</div>

Zusätzliche Decahose-Streams sind eine weitere Möglichkeit, die Zuverlässigkeit Ihrer Lösung zu erhöhen. Alle zusätzlichen Streams sind vollständig unabhängig und haben jeweils ihren eigenen Endpunkt. Jedem Stream wird ein eigenes stream\_label zugewiesen; dieses Label ist zusammen mit Ihrem Kontonamen Teil der URL des jeweiligen Streams. Siehe folgendes Beispiel:

https://gnip-stream.x.com/stream/sample10/accounts/:account\_name/publishers/twitter/:stream\_label.json

Die gängigste Praxis ist, einen Echtzeit-Stream für Ihr Produktivsystem bereitzustellen und einen weiteren Stream für Entwicklung und Tests vorzuhalten. Ein Test-/Entwicklungs-Stream ermöglicht Decahose-Kund:innen, Client-Consumer-Updates zu testen. Zwar kann jedem Stream ein beliebiges (eindeutiges) Label zugewiesen werden, häufig werden jedoch „prod“ für den Produktions-Stream sowie „dev“ oder „sandbox“ für einen zusätzlichen Entwicklungs-Stream verwendet.

Die Anzahl der Streams und ihre eindeutigen Labels werden von Ihrer/Ihrem Account-Ansprechpartner:in konfiguriert.

**Redundante Verbindungen**

Eine redundante Verbindung ermöglicht es Ihnen, mehr als eine gleichzeitige Verbindung zum Datenstream herzustellen. Dadurch erhalten Sie Redundanz, indem Sie mit zwei separaten Consumern auf denselben Stream zugreifen und über beide Verbindungen dieselben Daten empfangen. Ihre App verfügt so über ein Hot-Failover für verschiedene Situationen, z. B. wenn ein Stream getrennt wird oder der primäre Server Ihrer App ausfällt.

Die Anzahl der für einen bestimmten Stream zulässigen Verbindungen wird von Ihrer/Ihrem Account-Ansprechpartner:in konfiguriert. Um einen redundanten Stream zu verwenden, verbinden Sie sich einfach mit derselben URL wie für Ihre primäre Verbindung. Die Daten für Ihren Stream werden über beide Verbindungen gesendet; beide Stream-Verbindungen werden auf dem Stream-Dashboard angezeigt.

Beachten Sie, dass wir für Abrechnungszwecke die Aktivitätszählungen, die Sie über mehrere Verbindungen erhalten, deduplizieren, sodass Ihnen jede eindeutige Aktivität nur einmal in Rechnung gestellt wird. Da die Decahose zwei Partitionen hat, finden Sie nachfolgend ein Beispiel dafür, wie die Verbindungsanzahl funktioniert:

Connect to decahose partition=1
Connect to decahose partition=1
Connect to decahose partition=2

Die oben beschriebene Situation ergibt insgesamt drei Verbindungen – zwei Verbindungen zu partition=1 und eine Verbindung zu partition=2. In der Regel sollten Sie die gleiche Anzahl an Verbindungen zu jeder Partition haben. Dieses Beispiel verdeutlicht daher eine Situation, in der die redundante Verbindung zu partition=2 abgebrochen ist und Sie dies weiter untersuchen sollten.

**Wiederherstellung**

#### Übersicht 

Recovery ist ein Tool zur Datenwiederherstellung (nicht für die primäre Datenerfassung bestimmt), das Streaming-Zugriff auf ein fortlaufendes 5‑Tage-Fenster jüngster historischer X-Daten bietet. Es sollte verwendet werden, um Daten nachzuholen, wenn Ihre konsumierende Anwendung im Echtzeit-Stream Daten verpasst hat – sei es aufgrund einer kurzfristigen Trennung oder eines anderen Szenarios, in dem Ihnen über einen Zeitraum hinweg die Aufnahme von Echtzeitdaten nicht gelingt.

#### Verwendung von Recovery 

Mit dem Recovery-Stream kann Ihre App Anfragen stellen, die auf die gleiche Weise funktionieren wie Anfragen an die Echtzeit-Streams. Ihre App muss jedoch Parameter in der URL angeben, die das angeforderte Zeitfenster kennzeichnen. Anders ausgedrückt: Eine Recovery-Anfrage fordert die API auf: „Posts von Zeitpunkt A bis Zeitpunkt B.“ Diese Posts werden dann über Ihre Streaming-Verbindung in einer Weise zugestellt, die den Echtzeit-Stream nachahmt – allerdings mit einer geringfügig langsameren Rate als in Echtzeit. Siehe unten als Beispiel:

„https://stream-data-api.x.com/stream/powertrack/accounts/someAccountName/publishers/twitter/powertrack.json?startTime=2023-07-05T17:09:12.070Z“

Posts werden beginnend mit der ersten (ältesten) Minute des angegebenen Zeitraums geliefert und chronologisch fortgesetzt, bis die letzte Minute zugestellt ist. Anschließend wird eine „Recovery Request Completed“-Nachricht über die Verbindung gesendet, und der Server schließt die Verbindung. Wenn Ihre Anfrage zu einer Tageszeit beginnt, in der nur wenige oder keine passenden Ergebnisse aufgetreten sind, kann es eine Weile dauern, bis die ersten Ergebnisse geliefert werden – Daten werden zugestellt, sobald Recovery während der Verarbeitung dieses Archivabschnitts auf Treffer stößt. Wenn keine Ergebnisse zur Auslieferung verfügbar sind, sendet der Stream weiterhin Wagenrückläufe, also „Heartbeats“, über die Verbindung, um ein Timeout zu verhindern.

Recovery ist als Werkzeug gedacht, um Daten, die aufgrund kurzer Verbindungsabbrüche verpasst wurden, einfach nachzuholen – nicht für sehr lange Zeiträume wie einen ganzen Tag. Wenn Sie Daten über längere Zeiträume wiederherstellen müssen, empfehlen wir, längere Anfragen in kürzere Zeitfenster aufzuteilen (z. B. zwei Stunden), um das Risiko einer Trennung während der Anfrage durch Internetinstabilität oder andere Gründe zu verringern und mehr Transparenz über den Fortschritt langer Anfragen zu schaffen.

<div id="data-availability">
  #### Datenverfügbarkeit
</div>

Sie können die Wiederherstellungsfunktion verwenden, um verpasste Daten innerhalb der letzten 24 Stunden zu rekonstruieren, wenn Sie das 5‑Minuten‑Backfill‑Zeitfenster nicht zum erneuten Verbinden nutzen können.

Die Streaming‑Wiederherstellung bietet ein verlängertes Backfill‑Zeitfenster von 24 Stunden. Die Wiederherstellung ermöglicht es Ihnen, den Zeitraum mit fehlenden Daten „nachzuholen“. Ein Wiederherstellungs‑Stream wird gestartet, wenn Sie eine Verbindungsanfrage mit den Anfrageparametern 'start\_time' und 'end\_time' stellen. Nach dem Herstellen der Verbindung streamt die Wiederherstellung den angegebenen Zeitraum erneut und trennt anschließend die Verbindung.  

Sie können bis zu zwei gleichzeitige Wiederherstellungsanfragen stellen, d. h. „zwei Wiederherstellungs‑Jobs“. Technisch funktioniert die Wiederherstellung genauso wie Backfill, außer dass eine Start‑ und Endzeit definiert ist. Ein Wiederherstellungszeitraum umfasst genau einen zusammenhängenden Zeitbereich.

<div id="backfill">
  #### Backfill
</div>

Um Backfill anzufordern, müssen Sie Ihrer Verbindungsanfrage den Parameter backfillMinutes=N hinzufügen, wobei N die Anzahl der Minuten (1–5, nur ganze Zahlen) ist, die beim Herstellen der Verbindung aufgefüllt werden sollen. Wenn Sie sich beispielsweise für 90 Sekunden trennen, sollten Sie Ihrer Verbindungsanfrage backfillMinutes=2 hinzufügen. Da diese Anfrage Backfill für 2 Minuten bereitstellt, einschließlich des 30‑Sekunden‑Zeitraums vor Ihrer Trennung, muss Ihre _Consumer‑App tolerant gegenüber doppelten Daten_ sein.

Eine Beispiel‑URL für eine Decahose‑Verbindungsanfrage, die ein 5‑Minuten‑Backfill für Partition 1 anfordert, sieht so aus:

https://gnip-stream.x.com/stream/sample10/accounts/:account\_name/publishers/twitter/:stream\_label.json?partition=1\&backfillMinutes=5

**HINWEISE:**

- Sie können beim Herstellen der Verbindung stets „backfillMinutes=5“ verwenden und anschließend alle bereitgestellten doppelten Daten deduplizieren.
- Wenn Sie länger als fünf Minuten getrennt sind, können Sie Daten mit Recovery wiederherstellen.

**Wiederherstellung nach Trennung**

Das Neustarten und Wiederherstellen nach einer Trennung umfasst mehrere Schritte:

- Bestimmen der Dauer des Trennungszeitraums.
  - 5 Minuten oder weniger?
    - Wenn Sie Backfill für den Stream aktiviert haben, bereiten Sie die Verbindungsanfrage mit dem passenden Parameter „backfillMinutes“ vor.
  - Mehr als 5 Minuten?
    - Wenn Sie einen Recovery‑Stream haben, stellen Sie eine Recovery‑Anfrage für den getrennten Zeitraum (idealerweise mit Ihrem aktuellen Realtime‑Regelsatz, bei Bedarf über die Rules API).
- Eine neue Verbindung anfordern.

Wenn Sie Trennungen oder Ausfallzeiten erleben, finden Sie hier Strategien zur Minderung und Wiederherstellung:

1. **Backfill implementieren**
   Backfill ermöglicht es Ihnen, ab einem Zeitpunkt vor der Trennung von einer Stream‑Verbindung wieder zu verbinden und deckt Trennungen von bis zu 5 Minuten ab. Es wird implementiert, indem ein Parameter in die Verbindungsanfrage aufgenommen wird.

2. **Einen redundanten Stream von einem anderen Standort konsumieren**
   Wenn der redundante Stream in dieselbe Live‑Umgebung gestreamt werden kann und Daten dedupliziert werden, entfällt die Notwendigkeit einer Wiederherstellung, es sei denn, SOWOHL der normale als auch der redundante Stream haben gleichzeitig Ausfallzeiten oder Trennungen. Wenn der redundante Stream nicht live in die Produktionsumgebung gestreamt werden kann, kann er in einen separaten „Notfall“‑Datenspeicher geschrieben werden. Dann hat Ihr System im Falle von Trennungen oder Ausfallzeiten bei der primären Stream‑Verbindung Daten zur Hand, um Ihre primäre Datenbank für den Zeitraum zu füllen, in dem Daten fehlen.

3. **Recovery implementieren**
   Wenn Trennungen oder Ausfallzeiten sowohl den primären als auch den redundanten Stream betreffen, verwenden Sie Decahose Recovery, um alle fehlenden Daten wiederherzustellen. Die API bietet ein rollierendes Fenster, das 5 Tage des Archivs abdeckt, und wird am besten genutzt, indem Sie jeweils nicht mehr als eine Stunde dieses Fensters anfordern und einstreamen. Dies geschieht parallel zum Realtime‑Stream. Beachten Sie, dass wir keine Lösungen für die Wiederherstellung von Decahose‑Daten außerhalb des von Recovery bereitgestellten 5‑Tage‑Fensters haben. Es ist daher wichtig, einen redundanten Stream zu nutzen, um sicherzustellen, dass Sie auf Ihrer Seite eine vollständige Kopie der Daten haben, falls es zu erheblichen Ausfallzeiten auf Ihrer Seite kommt.

Wenn Sie anomale gespeicherte Datenmengen feststellen –
Mögliche Wege, fehlende Daten zu erkennen, obwohl keine Trennungen oder Ausfallzeiten aufgetreten sind …

1. Eingehende Posts zählen
   Ihr System sollte die rohe Anzahl der Posts zählen, die Sie ganz am Anfang Ihrer Ingestions‑App erhalten, und dann eine Möglichkeit bieten, diese Zahlen mit der Anzahl der Posts zu vergleichen, die Ihren endgültigen Datenspeicher erreicht. Abweichungen können überwacht werden und Ihr Team auf Probleme aufmerksam machen, durch die Daten nach dem Empfang verworfen werden.

2. Auf anomale gespeicherte Volumina analysieren
   Analysieren Sie außerdem die Volumina der gespeicherten Daten in Ihrer endgültigen Datenbank, um nach ungewöhnlichen Einbrüchen zu suchen. Dies kann ebenfalls auf Probleme hinweisen, auch wenn es Umstände geben wird, in denen Rückgänge im Volumen normal sind (z. B. wenn die X‑Plattform nicht verfügbar ist und Personen für einen gewissen Zeitraum keine Posts erstellen können).

<div id="api-reference">
  ## API-Referenz
</div>

<div id="decahose-stream">
  ### Decahose-Stream
</div>

Zum Abschnitt auf dieser Seite springen

[Methoden](/de/x-api/enterprise-gnip-2.0/fundamentals/decahose-api#methods)

[Authentifizierung](/de/x-api/enterprise-gnip-2.0/fundamentals/decahose-api#authentication)

[GET /\{stream-type}/:stream](/de/x-api/enterprise-gnip-2.0/fundamentals/decahose-api#get-stream-type-stream)

[Replay-API](/de/x-api/enterprise-gnip-2.0/fundamentals/decahose-api#replay-api)

<div id="methods">
  #### Methoden
</div>

| Methode | Beschreibung |
| :--- | :--- |
| [GET /\{stream-type}/:stream](#Stream) | Mit dem Datenstream verbinden |

<div id="authentication">
  #### Authentifizierung[](#authentication- "Permalink zu dieser Überschrift")
</div>

Alle Anfragen an die Volume-Stream-APIs müssen die HTTP-Authentifizierung „Basic“ verwenden, basierend auf einer gültigen Kombination aus E‑Mail-Adresse und Passwort, mit der Sie sich bei Ihrem Konto unter console.gnip.com anmelden. Die Zugangsdaten müssen bei jeder Anfrage im Authorization-Header übermittelt werden. Stellen Sie daher sicher, dass Ihr Client allen API-Anfragen den HTTP-Header „Authorization: Basic“ (mit über HTTPS codierten Zugangsdaten) hinzufügt.

#### GET \{stream-type}:stream

Stellt eine dauerhafte Verbindung zum Firehose-Stream her, über die die Echtzeitdaten übertragen werden.

<div id="request-specifications">
  #### Anfragespezifikationen
</div>

|     |     |
| :--- | :--- |
| **Anfragemethode** | HTTP GET |
| **Verbindungstyp** | Keep-Alive  <br />  <br />Dies sollte im Header der Anfrage angegeben werden. |
| **URL** | Zu finden auf der API-Hilfeseite des Streams in Ihrem Dashboard, mit der folgenden Struktur:  <br />  <br />Decahose:<br /><br />[https://gnip-stream.x.com/stream/sample10/accounts/:account\_name/publishers/twitter/:stream\_label.json?partition=1](https://gnip-stream.x.com/stream/sample10/accounts/:account_name/publishers/twitter/:stream_label.json?partition=1) |
| **Partition (erforderlich)** | `partition=\{#}` - Partitionierung ist jetzt erforderlich, um den vollständigen Stream zu nutzen. Sie müssen sich mit dem angegebenen Partition-Parameter mit dem Stream verbinden. Nachfolgend die Anzahl der Partitionen pro Stream:<br /><br />\* Decahose: 2 Partitionen |
| **Komprimierung** | Gzip. Um sich mit dem Stream unter Verwendung von Gzip-Komprimierung zu verbinden, senden Sie einfach einen Accept-Encoding-Header in der Verbindungsanfrage. Der Header sollte folgendermaßen aussehen:  <br />  <br />Accept-Encoding: gzip |
| **Zeichenkodierung** | UTF-8 |
| **Antwortformat** | JSON. Der Header Ihrer Anfrage sollte das JSON-Format für die Antwort angeben. |
| **Rate Limit** | 10 Anfragen pro 60 Sekunden. |
| **Backfill-Parameter** | Wenn Sie einen Stream mit aktiviertem Backfill erworben haben, müssen Sie den „backfillMinutes"-Parameter in die GET-Anfrage einfügen, um ihn zu aktivieren. |
| **Read Timeout** | Setzen Sie ein Read Timeout auf Ihrem Client und stellen Sie sicher, dass es auf einen Wert über 30 Sekunden gesetzt ist. |
| **Unterstützung für Tweet-Bearbeitungen** | Alle Tweet-Objekte enthalten Tweet-Bearbeitungsmetadaten, die den Bearbeitungsverlauf des Tweets beschreiben. Weitere Details finden Sie auf der [Grundlagenseite „Edit Tweets"](/de/x-api/enterprise-gnip-2.0/fundamentals/edit-tweets). |

<div id="responses">
  #### Antworten
</div>

Die folgenden Antworten können von der API für diese Anfragen zurückgegeben werden. Die meisten Fehlercodes enthalten im Body eine Zeichenfolge mit zusätzlichen Details. Bei Antworten ungleich 200 sollten Clients versuchen, die Verbindung erneut herzustellen.

| Status | Text | Beschreibung |
| :--- | :--- | :--- |
| 200 | Erfolg | Die Verbindung wurde erfolgreich geöffnet, und neue Aktivitäten werden gesendet, sobald sie eintreffen. |
| 401 | Nicht autorisiert | Die HTTP-Authentifizierung ist aufgrund ungültiger Anmeldedaten fehlgeschlagen. Melden Sie sich mit Ihren Anmeldedaten bei console.gnip.com an, um sicherzustellen, dass Sie diese in Ihrer Anfrage korrekt verwenden. |
| 406 | Nicht akzeptabel | Tritt im Allgemeinen auf, wenn Ihr Client die Header zur Annahme der gzip-Codierung vom Stream nicht korrekt setzt, kann jedoch auch unter anderen Umständen auftreten.  <br />  <br />Enthält eine JSON-Nachricht ähnlich: „Für diese Verbindung ist Komprimierung erforderlich. Um die Komprimierung zu aktivieren, senden Sie einen ‚Accept-Encoding: gzip‘-Header in Ihrer Anfrage und seien Sie darauf vorbereitet, den Stream beim Lesen auf Client-Seite zu dekomprimieren.“ |
| 429 | Ratenbegrenzt | Ihre App hat das Limit für Verbindungsanfragen überschritten. |
| 503 | Dienst nicht verfügbar | Twitter-Serverproblem. Stellen Sie die Verbindung mit exponentiellem Backoff-Muster erneut her. Wenn auf der [X API Status Page](https://api.twitterstat.us/) keine Mitteilung zu diesem Problem veröffentlicht wurde, wenden Sie sich an den Support oder den Notdienst, wenn nach 10 Minuten weiterhin keine Verbindung möglich ist. |

<div id="example-curl-request">
  #### Beispiel-cURL-Anfrage
</div>

Die folgende Beispielanfrage wird mit cURL in der Befehlszeile ausgeführt. Beachten Sie jedoch, dass diese Anfragen auch in der Programmiersprache Ihrer Wahl gesendet werden können:

```
curl --compressed -v -uexample@customer.com "https://gnip-stream.x.com/stream/firehose/accounts/:account\_name/publishers/twitter/:stream\_label.json?partition={#}"
```

<div id="replay-api">
  #### Replay-API
</div>

Die Replay-API ist eine wichtige Ergänzung zu Echtzeit-Volumen-Streams. Replay ist ein Datenwiederherstellungstool, das Streaming-Zugriff auf ein fortlaufendes Zeitfenster jüngster historischer Daten von X ermöglicht.