---
title: API de Decahose
---

<Note>
  Este endpoint se ha actualizado para incluir metadatos de edición de publicaciones. Obtén más información sobre estos metadatos en la [página de fundamentos "Editar publicaciones"](/es/x-api/enterprise-gnip-2.0/fundamentals/edit-tweets).
</Note>

<div id="decahose-stream">
  ### Flujo Decahose
</div>

[Enterprise](https://developer.x.com/en/products/x-api/enterprise)

_Esta es una API empresarial disponible únicamente dentro de nuestros niveles de acceso gestionado. Para usar esta API, primero debes configurar una cuenta con nuestro equipo de ventas para empresas. [Más información](https://developer.x.com/en/products/x-api/enterprise)_

Decahose entrega una muestra aleatoria del 10% del Firehose de X en tiempo real a través de una conexión de streaming. Esto se logra mediante un algoritmo de muestreo en tiempo real que selecciona los datos al azar, a la vez que permite la entrega con la baja latencia esperada a medida que X los envía a través del firehose.

A continuación se presentan algunas de las características disponibles con Decahose:

- **URL ampliadas y mejoradas:** desenrolla por completo las URL acortadas y proporciona metadatos adicionales (título y descripción de la página)
- **Particionamiento del flujo**: 2 particiones, cada una con el 50% del volumen del flujo de Decahose
- **Mayor confiabilidad**: diversidad geográfica de los sistemas de backend

Nota: Estos datos se entregan en lotes y no admiten filtrado adicional (p. ej., por palabras clave).

`ENTERPRISE`

<div id="streaming-likes">
  ### Transmisión de Me gusta
</div>

_Esta es una API para empresas disponible únicamente dentro de nuestros niveles de acceso gestionado. Para usar esta API, primero debe configurar una cuenta con nuestro equipo de ventas para empresas. [Más información](https://developer.x.com/en/products/x-api/enterprise)_

Los Me gusta permiten conocer quién indica que le gustan las Publicaciones y proporcionan recuentos precisos de Me gusta. Firehose y Decahose de Gnip pueden entregar Me gusta públicos relacionados con las Publicaciones suministradas a través de Gnip. Esto ofrece métricas de interacción pública y de audiencia en tiempo real asociadas con una Publicación.
 

**Introducción a los Me gusta**

A medida que se prepare para consumir datos de Me gusta, debe saber que:

- Los Me gusta se entregan mediante un flujo independiente y separado
- Históricamente, los Me gusta se denominaban “Favorites”. La carga útil del formato nativo enriquecido mantiene esta nomenclatura
- Los flujos incluyen solo Me gusta públicos
  - Público significa que el usuario que da Me gusta, el creador de la Publicación y la Publicación son públicos en la plataforma
- Los Me gusta son muy similares a los Retweets y representan una señal pública de interacción
- Los elementos de la carga útil incluyen:
  - Objeto de la Publicación original
  - Objeto del actor que creó la Publicación original
  - Objeto del actor que realizó la acción de Me gusta
- Solo se puede indicar Me gusta en contenido original
  - No se puede indicar Me gusta en Retweets. Un Me gusta de un Retweet se aplica a la Publicación original
  - Los Tweets citados _pueden_ recibir Me gusta
- Las actividades de Me gusta incluyen los Gnip Enrichments aplicables (cuando se hayan adquirido/aplicado)
- Productos / Funciones compatibles
  - Los flujos de Me gusta admiten Backfill (cuando se haya adquirido/aplicado)
  - No hay compatibilidad con Replay para los flujos de Me gusta
  - No hay compatibilidad con Search ni Historical para Me gusta
  - No hay planes inmediatos para agregar compatibilidad con Me gusta en PowerTrack

**Decahose**

- Para el 10% de Publicaciones de muestra entregadas en Decahose, el flujo incluye el 100% de los Me gusta públicos aplicables
- **Particiones:** 2
- **Estructura de URL**
  - https://gnip-stream.x.com/stream/sample10-likes/accounts/\<accountName>/publishers/twitter/\<streamLabel>.json?partition=1

**Carga útil en formato nativo enriquecido**

```json
{
   "id":"43560406e0ad9f68374445f5f30c33fc",
   "created_at":"Thu Dec 01 22:27:39 +0000 2016",
   "timestamp_ms":1480631259353,
   "favorited_status":{
      "created_at":"Thu Dec 01 22:27:16 +0000 2016",
      "id":804451830033948672,
      "id_str":"804451830033948672",
      "text":"@kafammheppduman",
      "source":"\u003ca href=\"http:\/\/x.com\/download\/android\" rel=\"nofollow\"\u003eX para Android\u003c\/a\u003e"
      "truncated":false,
      "in_reply_to_status_id":803694205163814912,
      "in_reply_to_status_id_str":"803694205163814912",
      "in_reply_to_user_id":2855759795,
      "in_reply_to_user_id_str":"2855759795",
      "in_reply_to_screen_name":"kafammheppduman",
      "user":{
         "id":2855759795,
         "id_str":"2855759795",
         "name":"delirdim kanka",
         "screen_name":"kafammheppduman",
         "location":"sanane",
         "url":"http:\/\/instagram.com\/kafammheppduman",
         "description":"Manit @GalatasaraySk \ud83d\udc9e",
         "translator_type":"none",
         "protected":false,
         "verified":false,
         "followers_count":3702,
         "friends_count":607,
         "listed_count":1,
         "favourites_count":113338,
         "statuses_count":389,
         "created_at":"Sat Nov 01 22:38:25 +0000 2014",
         "utc_offset":null,
         "time_zone":null,
         "geo_enabled":true,
         "lang":"tr",
         "contributors_enabled":false,
         "is_translator":false,
         "profile_background_color":"C0DEED",
         "profile_background_image_url":"",
         "profile_background_image_url_https":"",
         "profile_background_tile":false,
         "profile_link_color":"1DA1F2",
         "profile_sidebar_border_color":"C0DEED",
         "profile_sidebar_fill_color":"DDEEF6",
         "profile_text_color":"333333",
         "profile_use_background_image":true,
       "Profile_image_url": "http:\/\/pbs.twimg.com\/profile_images\/804421763945861121\/v3bp9pnq_normal.jpg",
         "Profile_image_url_https": "https:\/\/pbs.twimg.com\/profile_images\/804421763945861121\/v3bp9pnq_normal.jpg",
         "profile_banner_url":"https:\/\/pbs.twimg.com\/profile_banners\/2855759795\/1480630085",
         "default_profile":true,
         "default_profile_image":false,
         "following":null,
         "follow_request_sent":null,
         "notifications":null
      },
      "geo":null,
      "coordinates":null,
      "place":null,
      "contributors":null,
      "is_quote_status":false,
      "retweet_count":0,
      "favorite_count":0,
      "entities":{
         "hashtags":[],
         "urls":[],
         "user_mentions":[
            {
               "screen_name":"kafammheppduman",
               "name":"delirdim kanka",
               "id":2855759795,
               "id_str":"2855759795",
               "indices":[
                  0,
                  16
               ]
            }
         ],
         "symbols":[]
      },
      "favorited":false,
      "retweeted":false,
      "filter_level":"low",
      "lang":"und"
   },
   "user":{
      "id":774146932365070336,
      "id_str":"774146932365070336",
      "name":"Uyuyan Adam",
      "screen_name":"saykoMenn",
      "location":"Tarsus, T\u00fcrkiye",
      "url":"http:\/\/connected2.me\/pmc1i",
      "description":null,
      "translator_type":"none",
      "protected":false,
      "verified":false,
      "followers_count":414,
      "friends_count":393,
      "listed_count":0,
      "favourites_count":9868,
      "statuses_count":370,
      "created_at":"Fri Sep 09 07:26:26 +0000 2016",
      "utc_offset":null,
      "time_zone":null,
      "geo_enabled":false,
      "lang":"tr",
      "contributors_enabled":false,
      "is_translator":false,
      "profile_background_color":"F5F8FA",
      "profile_background_image_url":"",
      "profile_background_image_url_https":"",
      "profile_background_tile":false,
      "profile_link_color":"1DA1F2",
      "profile_sidebar_border_color":"C0DEED",
      "profile_sidebar_fill_color":"DDEEF6",
      "profile_text_color":"333333",
      "profile_use_background_image":true,
      "profile_image_url": "http:\/\/pbs.twimg.com\/profile_images\/802992813424201728\/VMzcTL3x_normal.jpg",
      "profile_image_url_https": "https:\/\/pbs.twimg.com\/profile_images\/802992813424201728\/VMzcTL3x_normal.jpg",
      "profile_banner_url":"https:\/\/pbs.twimg.com\/profile_banners\/774146932365070336\/1480283382",
      "default_profile":true,
      "default_profile_image":false,
      "following":null,
      "follow_request_sent":null,
      "notifications":null
   }
}
```

**Payload de “Eliminar Me gusta” / “Quitar Me gusta”**

```json
{
   "delete":{
      "favorite":{
         "tweet_id":696615514970279937,
         "tweet_id_str":"696615514970279937",
         "user_id":2510287578,
         "user_id_str":"2510287578"
      },
      "timestamp_ms":"1480437031205"
   }
}
```

<div id="guides">
  ## Guías
</div>

<div id="recovery-and-redundency">
  ### Recuperación y redundancia
</div>

**Introducción** 

La transmisión de altos volúmenes de Publicaciones en tiempo real requiere un conjunto de prácticas recomendadas que promuevan tanto la confiabilidad como la fidelidad íntegra de los datos. Al consumir datos en tiempo real, maximizar el tiempo de conexión es un objetivo fundamental. Cuando ocurran desconexiones, es importante detectarlas automáticamente y reconectarse. Tras reconectarse, es importante evaluar si hay periodos que deban rellenarse con datos faltantes. El componente que gestiona estos detalles y consume Publicaciones en tiempo real es solo una parte de un sistema con consideraciones de red, almacenes de datos, servidores y almacenamiento. Dada la complejidad de estos sistemas, otra práctica recomendada es disponer de distintos entornos de transmisión, con al menos flujos separados para desarrollo/pruebas y producción.

Decahose incluye un conjunto de funciones que ayudan en estos esfuerzos.

1. Para admitir múltiples entornos, podemos implementar [Flujos adicionales](#AdditionalStreams) para su cuenta. Estos flujos son independientes entre sí y tienen una etiqueta de flujo diferente para ayudar a diferenciarlos.
2. Para ayudar a mantener la conexión, cada flujo de Decahose admite [Conexiones redundantes](/es/x-api/enterprise-gnip-2.0/fundamentals/decahose-api#additional-streams). La arquitectura más común es que un flujo tenga dos conexiones y, del lado del cliente, haya dos consumidores independientes, idealmente en redes distintas. Con este diseño, puede haber redundancia en las redes del lado del cliente, los servidores y las rutas de los almacenes de datos. Tenga en cuenta que se sirve una copia completa de los datos en cada conexión y que el lado del cliente debe tolerar y gestionar datos duplicados.
3. Se enviará un «latido» cada 10 segundos; sin embargo, con el flujo Decahose, el volumen de datos es lo suficientemente alto como para que incluso una breve duración (p. ej., unos segundos) sin Publicaciones pueda indicar un problema de conexión. Por lo tanto, tanto un «silencio de datos» como la ausencia de latido pueden usarse para detectar una desconexión.

Dado que las desconexiones ocurren, el flujo Decahose cuenta con funciones dedicadas de [Recuperación](/es/x-api/enterprise-gnip-2.0/fundamentals/decahose-api#overview) y de [Relleno](/es/x-api/enterprise-gnip-2.0/fundamentals/decahose-api#backfill) para ayudar a recuperar datos que se hayan perdido por desconexiones y otros problemas operativos.

<div id="additional-streams">
  #### Flujos adicionales
</div>

Contar con flujos adicionales de Decahose es otra manera de aportar confiabilidad a su solución. Cualquier flujo adicional es completamente independiente y tiene su propio endpoint. A cada flujo se le asigna su propio stream\_label, y esta etiqueta, junto con el nombre de su cuenta, forman parte de la URL de ese flujo. Vea el siguiente ejemplo:

https://gnip-stream.x.com/stream/sample10/accounts/:account\_name/publishers/twitter/:stream\_label.json

La convención más común es contar con un flujo en tiempo real dedicado para su sistema de producción y otro flujo adicional disponible para desarrollo y pruebas. Disponer de un flujo de prueba/desarrollo permite a los clientes de Decahose validar actualizaciones de sus consumidores cliente. Si bien se puede asignar cualquier etiqueta (única) a un flujo, una convención es usar "prod" para el flujo de producción y "dev" o "sandbox" para un flujo adicional de desarrollo.

La cantidad de flujos y sus etiquetas únicas se configura con su representante de cuenta.

**Conexiones redundantes**

Una conexión redundante simplemente le permite establecer más de una conexión simultánea al flujo de datos. Esto aporta redundancia al permitirle conectarse al mismo flujo con dos consumidores distintos, recibiendo los mismos datos a través de ambas conexiones. Así, su app cuenta con conmutación por error en caliente para diversas situaciones, por ejemplo, cuando un flujo se desconecta o cuando falla el servidor principal de su app.

La cantidad de conexiones permitidas para un flujo determinado se configura con su representante de cuenta. Para usar un flujo redundante, simplemente conéctese a la misma URL utilizada para su conexión principal. Los datos de su flujo se enviarán por ambas conexiones, y ambas conexiones del flujo se representarán en el panel del flujo.

Tenga en cuenta que, para fines de facturación, desduplicamos los recuentos de actividad que recibe a través de múltiples conexiones, de modo que solo se le facture una vez por cada actividad única. Dado que Decahose tiene dos particiones, a continuación se muestra un ejemplo de cómo funciona el recuento de conexiones:

Connect to decahose partition=1
Connect to decahose partition=1
Connect to decahose partition=2

La situación anterior produce un total de tres conexiones: dos conexiones a partition=1 y una conexión a partition=2. Normalmente, querrá tener la misma cantidad de conexiones en cada partición, por lo que este ejemplo destaca una situación en la que la conexión redundante a partition=2 se ha caído y desea investigarla más a fondo.

**Recuperación**

#### Descripción general 

Recovery es una herramienta de recuperación de datos (no debe usarse para la recopilación principal de datos) que proporciona acceso en streaming a una ventana deslizante de 5 días de datos históricos recientes de X. Debe utilizarse para recuperar datos en escenarios en los que su aplicación consumidora pierda datos del flujo en tiempo real, ya sea por una desconexión de corta duración o por cualquier otro motivo que impida ingerir datos en tiempo real durante un período determinado.

#### Uso de Recovery 

Con el flujo de Recovery, tu app puede hacer solicitudes que funcionan de la misma manera que las solicitudes a los flujos en tiempo real. Sin embargo, tu app debe especificar parámetros en la URL que indiquen la ventana temporal que estás solicitando. En otras palabras, una solicitud de Recovery le pide a la API “Publicaciones desde la hora A hasta la hora B”. Estas publicaciones se entregan a través de tu conexión de streaming de una forma que imita el flujo en tiempo real, pero a una velocidad ligeramente inferior a la del tiempo real. Consulta el ejemplo a continuación:

"https://stream-data-api.x.com/stream/powertrack/accounts/someAccountName/publishers/twitter/powertrack.json?startTime=2023-07-05T17:09:12.070Z"

Las publicaciones se entregan comenzando por el primer (más antiguo) minuto del período especificado y continúan de forma cronológica hasta que se entregue el último minuto. En ese punto, se envía a través de la conexión un mensaje de Recovery Request Completed y, posteriormente, el servidor cierra la conexión. Si tu solicitud comienza en un momento del día en el que hubo pocos o ningún resultado coincidente, es probable que transcurra cierto tiempo antes de que se entreguen los primeros resultados; los datos se entregarán cuando Recovery encuentre coincidencias en la parte del archivo que se esté procesando en ese momento. Cuando no haya resultados disponibles para entregar, el flujo seguirá enviando retornos de carro, o “latidos”, a través de la conexión para evitar que se agote el tiempo de espera.

Recovery está diseñado como una herramienta para recuperar fácilmente datos perdidos debido a desconexiones breves, no para períodos muy largos como un día completo. Si surge la necesidad de recuperar datos durante períodos extensos, recomendamos dividir las solicitudes más largas en ventanas temporales más cortas (p. ej., dos horas) para reducir la posibilidad de una desconexión en medio de la solicitud debido a la volatilidad de Internet u otras razones y para proporcionar mayor visibilidad del progreso de solicitudes largas.

<div id="data-availability">
  #### Disponibilidad de datos
</div>

Puedes usar la función Recovery para recuperar datos perdidos en las últimas 24 horas si no puedes volver a conectarte dentro de la ventana de relleno retroactivo (backfill) de 5 minutos.

La función de recuperación de streaming te permite contar con una ventana de backfill ampliada de 24 horas. Recovery te permite “recuperar” el período de datos perdidos. Se inicia un flujo de recuperación cuando haces una solicitud de conexión usando los parámetros de solicitud "start\_time" y "end\_time". Una vez conectado, Recovery retransmitirá el período indicado y luego se desconectará.

Podrás realizar 2 solicitudes simultáneas a Recovery al mismo tiempo, es decir, “dos trabajos de recuperación”. Recovery funciona técnicamente de la misma manera que el backfill, excepto que se define una hora de inicio y una de fin. Un período de recuperación corresponde a un único intervalo de tiempo.

<div id="backfill">
  #### Relleno retroactivo
</div>

Para solicitar relleno retroactivo, debe agregar un parámetro backfillMinutes=N a su solicitud de conexión, donde N es la cantidad de minutos (1-5, solo números enteros) que se rellenarán cuando se establezca la conexión. Por ejemplo, si se desconecta durante 90 segundos, debe agregar backfillMinutes=2 a su solicitud de conexión. Dado que esta solicitud proporcionará relleno retroactivo durante 2 minutos, incluido el período de 30 segundos previo a su desconexión, su _app consumidora debe tolerar datos duplicados_.

Un ejemplo de URL de solicitud de conexión a Decahose, pidiendo un relleno retroactivo de 5 minutos para la partición 1, es:

https://gnip-stream.x.com/stream/sample10/accounts/:account\_name/publishers/twitter/:stream\_label.json?partition=1\&backfillMinutes=5

**NOTAS:**

- Sí, tiene la opción de usar siempre ‘backfillMinutes=5’ al conectarse y luego manejar cualquier dato duplicado que se proporcione.

- Si está desconectado por más de cinco minutos, puede recuperar datos usando Recovery.

**Recuperación tras una desconexión**

Reiniciar y recuperarse de una desconexión implica varios pasos:

- Determinar la duración del período de desconexión.
  - ¿5 minutos o menos?
    - Si tiene Backfill habilitado para el stream, prepare la solicitud de conexión con el parámetro ‘backfillMinutes’ apropiado.
  - ¿Más de 5 minutos?
    - Si tiene un stream de Recovery, haga una solicitud de Recovery para el período de desconexión (idealmente con su conjunto de reglas de tiempo real actual, usando la Rules API si es necesario).
- Solicitar una nueva conexión.

Cuando experimente desconexiones o tiempo de inactividad, estas son estrategias para mitigar y recuperarse en este escenario:

1. **Implementar relleno retroactivo**
   El relleno retroactivo le permite reconectarse desde un punto anterior a la desconexión de un stream y cubre desconexiones de hasta 5 minutos. Se implementa incluyendo un parámetro en la solicitud de conexión.

2. **Consumir un stream redundante desde otra ubicación**
   Si el stream redundante puede incorporarse al mismo entorno en vivo, con desduplicación de datos, eliminará la necesidad de recuperación a menos que TANTO el stream normal como el redundante sufran tiempo de inactividad o desconexiones simultáneas. Si el stream redundante no puede incorporarse en vivo al entorno de producción, puede escribirse en un almacén de datos “de emergencia” separado. Luego, en caso de desconexiones o tiempo de inactividad en la conexión del stream principal, su sistema tendrá datos disponibles para completar su base de datos principal durante el período en el que falten datos.

3. **Implementar Recovery**
   Cuando las desconexiones o el tiempo de inactividad afecten tanto al stream principal como al redundante, use Decahose Recovery para recuperar cualquier dato perdido. La API proporciona una ventana móvil que cubre 5 días del archivo y se aprovecha mejor solicitando no más de una hora de esa ventana a la vez y transmitiéndola. Esto se hace en paralelo al stream en tiempo real. Tenga en cuenta que no contamos con soluciones para recuperar datos de Decahose más allá de la ventana de 5 días proporcionada por Recovery, por lo que es importante que utilice un stream redundante para asegurarse de tener una copia completa de los datos de su lado en caso de un tiempo de inactividad significativo.

Cuando detecte volúmenes anómalos de datos almacenados-
Formas potenciales de detectar datos faltantes cuando no hubo desconexiones ni tiempo de inactividad…

1. Contar las publicaciones entrantes
   Su sistema debe contar el número bruto de publicaciones que recibe al inicio de su app de ingesta y luego proporcionar una forma de comparar esos números con el número de publicaciones que llegan a su almacén de datos final. Cualquier diferencia puede monitorearse y alertar a su equipo sobre problemas que provocan la pérdida de datos después de su recepción.

2. Analizar si hay volúmenes almacenados anómalos
   También puede analizar los volúmenes de datos almacenados en su base de datos final para identificar caídas anómalas. Esto también puede indicar problemas, aunque probablemente habrá circunstancias en las que las caídas de volumen sean normales (p. ej., si la plataforma X no está disponible y las personas no pueden crear publicaciones durante algún período de tiempo).

<div id="api-reference">
  ## Referencia de la API
</div>

<div id="decahose-stream">
  ### Flujo Decahose
</div>

Ir a en esta página

[Métodos](/es/x-api/enterprise-gnip-2.0/fundamentals/decahose-api#methods)

[Autenticación](/es/x-api/enterprise-gnip-2.0/fundamentals/decahose-api#authentication)

[GET /\{stream-type}/:stream](/es/x-api/enterprise-gnip-2.0/fundamentals/decahose-api#get-stream-type-stream)

[API de repetición](/es/x-api/enterprise-gnip-2.0/fundamentals/decahose-api#replay-api)

<div id="methods">
  #### Métodos
</div>

| Método | Descripción |
| :--- | :--- |
| [GET /\{stream-type}/:stream](#Stream) | Conectar al flujo de datos |

<div id="authentication">
  #### Autenticación[](#authentication- "Enlace permanente a este encabezado")
</div>

Todas las solicitudes a las API de Volume Stream deben usar autenticación básica HTTP, construida a partir de una combinación válida de dirección de correo electrónico y contraseña que utilice para iniciar sesión en su cuenta en console.gnip.com. Las credenciales deben enviarse en el encabezado Authorization en cada solicitud. Por lo tanto, confirme que su cliente esté agregando el encabezado HTTP "Authorization: Basic" (con las credenciales codificadas sobre HTTPS) a todas las solicitudes de la API.

#### GET \{stream-type}:stream

Establece una conexión persistente con el flujo Firehose, a través de la cual se entregarán los datos en tiempo real.

<div id="request-specifications">
  #### Especificaciones de la solicitud
</div>

|     |     |
| :--- | :--- |
| **Método de la solicitud** | HTTP GET |
| **Tipo de conexión** | Keep-Alive  <br />  <br />Esto debe especificarse en el encabezado de la solicitud. |
| **URL** | Se encuentra en la página de Ayuda de la API del stream en su panel, con la siguiente estructura:  <br />  <br />Decahose:<br /><br />[https://gnip-stream.x.com/stream/sample10/accounts/:account\_name/publishers/twitter/:stream\_label.json?partition=1](https://gnip-stream.x.com/stream/sample10/accounts/:account_name/publishers/twitter/:stream_label.json?partition=1) |
| **Partición (obligatorio)** | `partition=\{#}` - Ahora la partición es obligatoria para consumir el stream completo. Deberá conectarse al stream con el parámetro de partición especificado. A continuación se muestra el número de particiones por stream:<br /><br />\* Decahose: 2 particiones |
| **Compresión** | Gzip. Para conectarse al stream usando compresión Gzip, simplemente envíe un encabezado Accept-Encoding en la solicitud de conexión. El encabezado debe verse así:  <br />  <br />Accept-Encoding: gzip |
| **Codificación de caracteres** | UTF-8 |
| **Formato de respuesta** | JSON. El encabezado de su solicitud debe especificar formato JSON para la respuesta. |
| **Límite de frecuencia** | 10 solicitudes por 60 segundos. |
| **Parámetro de Backfill** | Si adquirió un stream con Backfill habilitado, deberá agregar el parámetro "backfillMinutes" en la solicitud GET para habilitarlo. |
| **Tiempo de espera de lectura** | Configure un tiempo de espera de lectura en su cliente y asegúrese de que esté establecido en un valor superior a 30 segundos. |
| **Compatibilidad con ediciones de Tweets** | Todos los objetos de Tweet incluirán metadatos de edición del Tweet que describen su historial de ediciones. Consulte la página de fundamentos ["Edit Tweets"](/es/x-api/enterprise-gnip-2.0/fundamentals/edit-tweets) para más detalles. |

<div id="responses">
  #### Respuestas
</div>

La API puede devolver las siguientes respuestas para estas solicitudes. La mayoría de los códigos de error se devuelven con una cadena que incluye detalles adicionales en el cuerpo. Para respuestas distintas de 200, los clientes deben intentar reconectarse.

| Estado | Texto | Descripción |
| :--- | :--- | :--- |
| 200 | Correcto | La conexión se abrió correctamente y se enviarán nuevas actividades a medida que lleguen. |
| 401 | No autorizado | La autenticación HTTP falló debido a credenciales no válidas. Inicie sesión en console.gnip.com con sus credenciales para confirmar que las está utilizando correctamente en su solicitud. |
| 406 | No aceptable | Por lo general, esto ocurre cuando su cliente no incluye correctamente los encabezados para aceptar la codificación gzip del flujo, aunque también puede darse en otras circunstancias.  <br />  <br />Contendrá un mensaje JSON similar a: "Esta conexión requiere compresión. Para habilitar la compresión, envíe un encabezado 'Accept-Encoding: gzip' en su solicitud y prepárese para descomprimir el flujo a medida que el cliente lo lea." |
| 429 | Límite de tasa | Su aplicación ha superado el límite de solicitudes de conexión. |
| 503 | Servicio no disponible | Problema del servidor de Twitter. Vuelva a conectarse usando un patrón de retroceso exponencial. Si no se ha publicado ningún aviso sobre este problema en la [Página de estado de la API de X](https://api.twitterstat.us/), contacte al soporte o al canal de emergencia si no puede conectarse después de 10 minutos. |

<div id="example-curl-request">
  #### Ejemplo de solicitud con curl
</div>

La siguiente solicitud de ejemplo se realiza con curl en la línea de comandos. No obstante, tenga en cuenta que estas solicitudes también pueden enviarse con el lenguaje de programación de su preferencia:

```
curl --compressed -v -uexample@customer.com "https://gnip-stream.x.com/stream/firehose/accounts/:account\_name/publishers/twitter/:stream\_label.json?partition={#}"
```

<div id="replay-api">
  #### API de Replay
</div>

La API de Replay es un complemento importante para los flujos de Volumen en tiempo real. Replay es una herramienta de recuperación de datos que ofrece acceso en streaming a una ventana continua de datos históricos recientes de X.