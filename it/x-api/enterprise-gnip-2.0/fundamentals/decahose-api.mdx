---
title: API Decahose
---

<Note>
  Questo endpoint è stato aggiornato per includere i metadati delle modifiche ai post. Per saperne di più su questi metadati, consulta la pagina delle nozioni di base ["Modifica dei post"](/it/x-api/enterprise-gnip-2.0/fundamentals/edit-tweets). 
</Note>

<div id="decahose-stream">
  ### Flusso Decahose
</div>

[Enterprise](https://developer.x.com/en/products/x-api/enterprise)

_Questa è un’API enterprise disponibile solo nei nostri livelli di accesso gestiti. Per utilizzare questa API, devi prima attivare un account tramite il nostro team commerciale enterprise. [Scopri di più](https://developer.x.com/en/products/x-api/enterprise)_

Decahose fornisce un campione casuale del 10% del Firehose di X in tempo reale tramite una connessione in streaming. Questo avviene mediante un algoritmo di campionamento in tempo reale che seleziona i dati in modo casuale, garantendo al contempo la prevista consegna a bassa latenza man mano che X invia i dati attraverso il firehose.

Di seguito alcune delle funzionalità disponibili con Decahose:

- **URL espansi e arricchiti:** - risolve completamente gli URL abbreviati e fornisce metadati aggiuntivi (titolo e descrizione della pagina)
- **Partizionamento dello stream** - 2 partizioni, ciascuna contenente il 50% del volume del flusso Decahose
- **Affidabilità migliorata** - diversità geografica dei sistemi backend

Nota: questi dati vengono forniti in blocco e non supportano filtri aggiuntivi (ad es. per parole chiave).

`ENTERPRISE`

<div id="streaming-likes">
  ### Mi piace in streaming
</div>

_Questa è un'API per clienti enterprise disponibile solo nei nostri livelli di accesso gestiti. Per utilizzare questa API, devi prima configurare un account con il nostro team commerciale enterprise. [Scopri di più](https://developer.x.com/en/products/x-api/enterprise)_

I Mi piace forniscono visibilità su chi apprezza i Post e conteggi accurati dei Mi piace. Firehose e Decahose di Gnip possono fornire i Mi piace pubblici relativi ai Post consegnati tramite Gnip. Questo consente metriche in tempo reale di coinvolgimento pubblico e di audience associate a un Post.

**Introduzione ai Mi piace**

Quando ti prepari a utilizzare i dati sui Mi piace, tieni presente che:

- I Mi piace sono forniti tramite uno stream indipendente e separato
- Storicamente i Mi piace sono stati chiamati “Favorites”. Il payload nel formato nativo arricchito mantiene questa nomenclatura
- Gli stream includono solo Mi piace pubblici
  - Pubblici significa che l'utente che mette Mi piace, il creatore del Post e il Post sono tutti pubblici sulla piattaforma
- I Mi piace sono molto simili ai Retweet e rappresentano un segnale pubblico di coinvolgimento
- Gli elementi del payload includono:
  - Oggetto Post originale
  - Oggetto Actor che ha creato il Post originale
  - Oggetto Actor che ha eseguito l'azione di Mi piace
- Solo i contenuti originali possono ricevere Mi piace
  - I Retweet non possono ricevere Mi piace. Un Mi piace a un Retweet viene applicato al Post originale
  - I Tweet citati _possono_ ricevere Mi piace
- Le attività di Mi piace includono le Gnip Enrichments applicabili (se acquistate/applicate)
- Prodotti/Funzionalità supportati
  - Gli stream di Mi piace supportano il Backfill (se acquistato/applicato)
  - Non è previsto il supporto Replay per gli stream di Mi piace
  - Non è previsto il supporto Search o Historical per i Mi piace
  - Al momento non ci sono piani per aggiungere il supporto dei Mi piace a PowerTrack

**Decahose**

- Per il campione del 10% di Post fornito in Decahose, lo stream include il 100% dei Mi piace pubblici applicabili
- **Partizioni:** 2
- **Struttura URL**
  - https://gnip-stream.x.com/stream/sample10-likes/accounts/\<accountName>/publishers/twitter/\<streamLabel>.json?partition=1

**Payload nel formato nativo arricchito**

```json
{
   "id":"43560406e0ad9f68374445f5f30c33fc",
   "created_at":"Thu Dec 01 22:27:39 +0000 2016",
   "timestamp_ms":1480631259353,
   "favorited_status":{
      "created_at":"Thu Dec 01 22:27:16 +0000 2016",
      "id":804451830033948672,
      "id_str":"804451830033948672",
      "text":"@kafammheppduman",
      "source":"\u003ca href=\"http:\/\/x.com\/download\/android\" rel=\"nofollow\"\u003eX per Android\u003c\/a\u003e"
      "truncated":false,
      "in_reply_to_status_id":803694205163814912,
      "in_reply_to_status_id_str":"803694205163814912",
      "in_reply_to_user_id":2855759795,
      "in_reply_to_user_id_str":"2855759795",
      "in_reply_to_screen_name":"kafammheppduman",
      "user":{
         "id":2855759795,
         "id_str":"2855759795",
         "name":"delirdim kanka",
         "screen_name":"kafammheppduman",
         "location":"sanane",
         "url":"http:\/\/instagram.com\/kafammheppduman",
         "description":"Manit @GalatasaraySk \ud83d\udc9e",
         "translator_type":"none",
         "protected":false,
         "verified":false,
         "followers_count":3702,
         "friends_count":607,
         "listed_count":1,
         "favourites_count":113338,
         "statuses_count":389,
         "created_at":"Sat Nov 01 22:38:25 +0000 2014",
         "utc_offset":null,
         "time_zone":null,
         "geo_enabled":true,
         "lang":"tr",
         "contributors_enabled":false,
         "is_translator":false,
         "profile_background_color":"C0DEED",
         "profile_background_image_url":"",
         "profile_background_image_url_https":"",
         "profile_background_tile":false,
         "profile_link_color":"1DA1F2",
         "profile_sidebar_border_color":"C0DEED",
         "profile_sidebar_fill_color":"DDEEF6",
         "profile_text_color":"333333",
         "profile_use_background_image":true,
       "Profile_image_url": "http:\/\/pbs.twimg.com\/profile_images\/804421763945861121\/v3bp9pnq_normal.jpg",
         "Profile_image_url_https": "https:\/\/pbs.twimg.com\/profile_images\/804421763945861121\/v3bp9pnq_normal.jpg",
         "profile_banner_url":"https:\/\/pbs.twimg.com\/profile_banners\/2855759795\/1480630085",
         "default_profile":true,
         "default_profile_image":false,
         "following":null,
         "follow_request_sent":null,
         "notifications":null
      },
      "geo":null,
      "coordinates":null,
      "place":null,
      "contributors":null,
      "is_quote_status":false,
      "retweet_count":0,
      "favorite_count":0,
      "entities":{
         "hashtags":[],
         "urls":[],
         "user_mentions":[
            {
               "screen_name":"kafammheppduman",
               "name":"delirdim kanka",
               "id":2855759795,
               "id_str":"2855759795",
               "indices":[
                  0,
                  16
               ]
            }
         ],
         "symbols":[]
      },
      "favorited":false,
      "retweeted":false,
      "filter_level":"low"
      "lang":"und"
   },
   "user":{
      "id":774146932365070336,
      "id_str":"774146932365070336",
      "name":"Uyuyan Adam",
      "screen_name":"saykoMenn",
      "location":"Tarsus, T\u00fcrkiye",
      "url":"http:\/\/connected2.me\/pmc1i",
      "description":null,
      "translator_type":"none",
      "protected":false,
      "verified":false,
      "followers_count":414,
      "friends_count":393,
      "listed_count":0,
      "favourites_count":9868,
      "statuses_count":370,
      "created_at":"Fri Sep 09 07:26:26 +0000 2016",
      "utc_offset":null,
      "time_zone":null,
      "geo_enabled":false,
      "lang":"tr",
      "contributors_enabled":false,
      "is_translator":false,
      "profile_background_color":"F5F8FA",
      "profile_background_image_url":"",
      "profile_background_image_url_https":"",
      "profile_background_tile":false,
      "profile_link_color":"1DA1F2",
      "profile_sidebar_border_color":"C0DEED",
      "profile_sidebar_fill_color":"DDEEF6",
      "profile_text_color":"333333",
      "profile_use_background_image":true,
      "profile_image_url":"http://pbs.twimg.com/profile_images/802992813424201728/VMzcTL3x_normal.jpg",
      "profile_image_url_https":"https://pbs.twimg.com/profile_images/802992813424201728/VMzcTL3x_normal.jpg",
      "profile_banner_url":"https://pbs.twimg.com/profile_banners/774146932365070336/1480283382",
      "default_profile":true,
      "default_profile_image":false,
      "following":null,
      "follow_request_sent":null,
      "notifications":null
   }
}
```

**Payload di rimozione Mi piace / “Annulla Mi piace”**

```json
{
   "delete":{
      "favorite":{
         "tweet_id":696615514970279937,
         "tweet_id_str":"696615514970279937",
         "user_id":2510287578,
         "user_id_str":"2510287578"
      },
      "timestamp_ms":"1480437031205"
   }
}
```

<div id="guides">
  ## Guide
</div>

<div id="recovery-and-redundency">
  ### Ripristino e ridondanza
</div>

**Introduzione** 

Con lo streaming di volumi elevati di Post in tempo reale, si applica un insieme di best practice che favoriscono sia l’affidabilità dei dati sia la loro piena fedeltà. Quando si consumano dati in tempo reale, massimizzare il tempo di connessione è un obiettivo fondamentale. In caso di disconnessione, è importante rilevarla automaticamente e riconnettersi. Dopo la riconnessione, è importante valutare se ci siano periodi per cui eseguire il backfill dei dati. Il componente che gestisce questi aspetti e consuma Post in tempo reale è solo una parte di un sistema con considerazioni relative a rete, datastore, server e storage. Data la complessità di questi sistemi, un’altra best practice è prevedere ambienti di streaming distinti, con almeno flussi separati per sviluppo/test e produzione.

Decahose include un set di funzionalità che supportano questi obiettivi.

1. Per supportare più ambienti, possiamo distribuire [Additional Streams](#AdditionalStreams) per il tuo account. Questi flussi sono indipendenti tra loro e hanno etichette stream\_label diverse per facilitarne la distinzione.
2. Per contribuire al mantenimento della connessione, ogni flusso Decahose supporta [Redundant Connections](/it/x-api/enterprise-gnip-2.0/fundamentals/decahose-api#additional-streams). L’architettura più comune prevede che un flusso abbia due connessioni e, lato client, due consumer indipendenti – idealmente su reti diverse. Con questo design, può esserci ridondanza tra reti lato client, server e percorsi del datastore. Nota che su ciascuna connessione viene fornita una copia completa dei dati e il lato client deve tollerare e gestire i duplicati.
3. Un “heartbeat” verrà inviato ogni 10 secondi; tuttavia, con il flusso Decahose, il volume di dati è sufficientemente elevato che anche una breve durata (ad esempio, pochi secondi) senza Post può indicare un problema di connessione. Pertanto, sia un “silenzio dei dati” sia la mancanza di un heartbeat possono essere utilizzati per rilevare una disconnessione.

Poiché le disconnessioni si verificheranno, il flusso Decahose dispone di funzionalità dedicate di [Recovery](/it/x-api/enterprise-gnip-2.0/fundamentals/decahose-api#overview) e [Backfill](/it/x-api/enterprise-gnip-2.0/fundamentals/decahose-api#backfill) per aiutare a recuperare i dati persi a causa di disconnessioni e altri problemi operativi.

<div id="additional-streams">
  #### Flussi aggiuntivi
</div>

Disporre di flussi Decahose aggiuntivi è un altro modo per aumentare l’affidabilità della tua soluzione. Eventuali flussi aggiuntivi sono completamente indipendenti, con un proprio endpoint univoco. A ciascun flusso viene assegnata la propria stream\_label e questa etichetta, insieme al nome del tuo account, fa parte dell’URL di quel flusso. Vedi l’esempio seguente:

https://gnip-stream.x.com/stream/sample10/accounts/:account\_name/publishers/twitter/:stream\_label.json

La convenzione più comune è avere un flusso in tempo reale dedicato all’ambiente di produzione e un flusso aggiuntivo disponibile per sviluppo e test. Disporre di un flusso di test/sviluppo consente ai clienti Decahose di testare gli aggiornamenti dei consumer client. Sebbene a un flusso possa essere assegnata qualsiasi etichetta (univoca), una convenzione è usare “prod” per il flusso di produzione e “dev” o “sandbox” per un flusso di sviluppo aggiuntivo.

Il numero di flussi e le loro etichette univoche è configurabile dal tuo referente di account.

**Connessioni ridondanti**

Una connessione ridondante consente semplicemente di stabilire più di una connessione simultanea al flusso di dati. Questo fornisce ridondanza permettendoti di connetterti allo stesso flusso con due consumer separati, ricevendo gli stessi dati tramite entrambe le connessioni. In tal modo, la tua app dispone di un hot failover per varie situazioni, ad esempio quando un flusso viene disconnesso o quando il server primario della tua app subisce un guasto.

Il numero di connessioni consentite per un determinato flusso è configurabile dal tuo referente di account. Per utilizzare un flusso ridondante, connettiti semplicemente allo stesso URL usato per la tua connessione primaria. I dati del tuo flusso verranno inviati attraverso entrambe le connessioni, con entrambe le connessioni del flusso rappresentate sulla dashboard del flusso.

Nota che, ai fini della fatturazione, eseguiamo la deduplicazione dei conteggi delle attività che ricevi tramite più connessioni, in modo che ti venga addebitata ogni attività univoca una sola volta. Poiché Decahose ha due partizioni, ecco un esempio di come funziona il conteggio delle connessioni:

Connect to decahose partition=1
Connect to decahose partition=1
Connect to decahose partition=2

La situazione sopra produce un totale di tre connessioni: due connessioni a partition=1 e una connessione a partition=2. Normalmente, desidereresti lo stesso numero di connessioni per ciascuna partizione, quindi questo esempio evidenzia una situazione in cui la connessione ridondante a partition=2 è caduta e occorre indagare ulteriormente.

**Ripristino**

#### Panoramica 

Recovery è uno strumento per il ripristino dei dati (da non utilizzare per la raccolta primaria) che offre accesso in streaming a una finestra mobile di 5 giorni dei dati storici recenti di X. Va utilizzato per recuperare dati quando l’applicazione che consuma il flusso perde eventi in tempo reale, ad esempio per una breve disconnessione o in qualsiasi altro caso in cui non si riesca a ingerire dati in tempo reale per un certo periodo.

#### Utilizzo di Recovery 

Con il flusso Recovery, la tua app può effettuare richieste che funzionano nello stesso modo delle richieste ai flussi in tempo reale. Tuttavia, la tua app deve specificare nell’URL i parametri che indicano la finestra temporale richiesta. In altre parole, una richiesta Recovery chiede all’API “Post dall’ora A all’ora B”. Questi post vengono poi consegnati tramite la connessione in streaming in modo che imita il flusso in tempo reale, ma a una velocità leggermente inferiore al tempo reale. Vedi sotto un esempio:

"https://stream-data-api.x.com/stream/powertrack/accounts/someAccountName/publishers/twitter/powertrack.json?startTime=2023-07-05T17:09:12.070Z"

I post vengono consegnati a partire dal primo (più vecchio) minuto del periodo temporale specificato, proseguendo in ordine cronologico fino alla consegna dell’ultimo minuto. A quel punto, viene inviato attraverso la connessione un messaggio “Recovery Request Completed” e il server chiude la connessione. Se la tua richiesta inizia in un momento della giornata in cui si sono verificati pochi o nessun risultato corrispondente, potrebbe trascorrere un po’ di tempo prima che vengano consegnati i primi risultati: i dati verranno consegnati quando Recovery troverà corrispondenze nella porzione dell’archivio che sta elaborando in quel momento. Quando non ci sono risultati da consegnare, il flusso continuerà a inviare ritorni a capo, o “heartbeat”, attraverso la connessione per evitare il timeout.

Recovery è pensato come strumento per recuperare facilmente i dati persi a causa di brevi disconnessioni, non per periodi molto lunghi come un’intera giornata. Se si rende necessario recuperare dati per periodi estesi, consigliamo di suddividere le richieste più lunghe in finestre temporali più brevi (ad es. due ore) per ridurre la possibilità di disconnessione a richiesta in corso dovuta a instabilità della rete o altri motivi e per fornire maggiore visibilità sull’avanzamento delle richieste lunghe.

<div id="data-availability">
  #### Disponibilità dei dati
</div>

Puoi usare la funzionalità Recovery per recuperare i dati persi nelle ultime 24 ore se non riesci a riconnetterti entro la finestra di backfill di 5 minuti.

La funzionalità di recovery dello streaming consente di estendere la finestra di backfill a 24 ore. Recovery permette di “recuperare” l’intervallo di tempo dei dati mancanti. Un flusso di recovery viene avviato quando invii una richiesta di connessione usando i parametri 'start\_time' ed 'end\_time'. Una volta connesso, Recovery ritrasmetterà l’intervallo indicato e poi si disconnetterà.  

Puoi effettuare 2 richieste concorrenti a Recovery contemporaneamente, ossia “due job di recovery”. Recovery funziona tecnicamente nello stesso modo del backfill, tranne per il fatto che viene definito un orario di inizio e di fine. Un periodo di recovery riguarda un singolo intervallo temporale.

<div id="backfill">
  #### Backfill
</div>

Per richiedere il backfill, è necessario aggiungere il parametro backfillMinutes=N alla richiesta di connessione, dove N è il numero di minuti (1-5, solo numeri interi) da recuperare quando viene stabilita la connessione. Ad esempio, se ti disconnetti per 90 secondi, dovresti aggiungere backfillMinutes=2 alla richiesta di connessione. Poiché questa richiesta fornirà il backfill per 2 minuti, incluso il periodo di 30 secondi precedente alla disconnessione, la tua _applicazione consumer deve tollerare dati duplicati_.

Un esempio di URL di richiesta di connessione Decahose, che richiede un backfill di 5 minuti per la partizione 1, è il seguente:

https://gnip-stream.x.com/stream/sample10/accounts/:account\_name/publishers/twitter/:stream\_label.json?partition=1\&backfillMinutes=5

**NOTE:**

- Puoi scegliere di utilizzare sempre “backfillMinutes=5” quando ti connetti, gestendo poi gli eventuali dati duplicati forniti.

- Se rimani disconnesso per più di cinque minuti, puoi recuperare i dati utilizzando Recovery.

**Ripristino dopo la disconnessione**

Il riavvio e il ripristino dopo una disconnessione prevedono diversi passaggi:

- Determinare la durata del periodo di disconnessione.
  - 5 minuti o meno?
    - Se hai il Backfill abilitato per lo stream, prepara la richiesta di connessione con il parametro “backfillMinutes” appropriato.
  - Più di 5 minuti?
    - Se hai uno stream di Recovery, effettua una richiesta di Recovery per il periodo di disconnessione (idealmente con il tuo set di regole realtime corrente, utilizzando la Rules API se necessario).
- Richiedere una nuova connessione.

Quando si verificano disconnessioni o tempi di inattività, ecco alcune strategie per mitigare e ripristinare in questo scenario:

1. **Implementare il backfill**
   Il backfill consente di riconnettersi a partire da un punto precedente alla disconnessione da uno stream e copre disconnessioni fino a 5 minuti. Si implementa includendo un parametro nella richiesta di connessione.

2. **Consumare uno stream ridondante da un’altra sede**
   Se lo stream ridondante può essere inviato nello stesso ambiente live, con deduplicazione dei dati, eliminerai la necessità di recovery a meno che SIA lo stream normale SIA quello ridondante non subiscano contemporaneamente tempi di inattività o disconnessioni. Se lo stream ridondante non può essere trasmesso live nell’ambiente di produzione, può essere scritto in un archivio dati “di emergenza” separato. In tal caso, in presenza di disconnessioni o downtime sulla connessione dello stream primario, il sistema avrà dati pronti per colmare il database primario per il periodo di mancanza.

3. **Implementare Recovery**
   Quando disconnessioni o tempi di inattività interessano sia lo stream primario sia quello ridondante, utilizza Decahose Recovery per recuperare i dati mancanti. L’API fornisce una finestra scorrevole che copre 5 giorni dell’archivio ed è preferibile utilizzarla richiedendo non più di un’ora alla volta di tale finestra, trasmettendola in streaming. Questo avviene in parallelo allo stream realtime. Nota che non esistono soluzioni per recuperare dati Decahose oltre la finestra di 5 giorni fornita da Recovery, quindi è importante utilizzare uno stream ridondante per garantire di avere una copia completa dei dati lato tuo in caso di tempi di inattività significativi.

Quando rilevi volumi di dati archiviati anomali —
Possibili modi per individuare dati mancanti quando non si sono verificate disconnessioni o tempi di inattività…

1. Conteggiare i Post in ingresso
   Il tuo sistema dovrebbe conteggiare il numero grezzo di Post ricevuti all’inizio dell’app di ingestion, quindi fornire un modo per confrontare tali numeri con il numero di Post che raggiunge l’archivio dati finale. Eventuali differenze possono essere monitorate e segnalare al team problemi che causano la perdita di dati dopo la ricezione.

2. Analizzare volumi archiviati anomali
   Potresti anche analizzare i volumi di dati archiviati nel database finale per individuare cali anomali. Questo può indicare problemi, sebbene sia probabile che vi siano circostanze in cui cali di volume siano normali (ad es. se la piattaforma X non è disponibile e le persone non possono creare Post per un certo periodo di tempo).

<div id="api-reference">
  ## Riferimento API
</div>

<div id="decahose-stream">
  ### Flusso Decahose
</div>

Vai a:

[Metodi](/it/x-api/enterprise-gnip-2.0/fundamentals/decahose-api#methods)

[Autenticazione](/it/x-api/enterprise-gnip-2.0/fundamentals/decahose-api#authentication)

[GET /\{stream-type}/:stream](/it/x-api/enterprise-gnip-2.0/fundamentals/decahose-api#get-stream-type-stream)

[API di replay](/it/x-api/enterprise-gnip-2.0/fundamentals/decahose-api#replay-api)

<div id="methods">
  #### Metodi
</div>

| Metodo | Descrizione |
| :--- | :--- |
| [GET /\{stream-type}/:stream](#Stream) | Connetti al flusso di dati |

<div id="authentication">
  #### Autenticazione[](#authentication- "Permalink a questo titolo")
</div>

Tutte le richieste alle API Volume Stream devono utilizzare l’autenticazione HTTP Basic, creata a partire da una combinazione valida di indirizzo email e password usata per accedere al tuo account su console.gnip.com. Le credenziali devono essere inviate come intestazione Authorization per ogni richiesta. Verifica quindi che il tuo client aggiunga l’intestazione HTTP "Authorization: Basic" (con credenziali codificate su HTTPS) a tutte le richieste API.

#### GET \{stream-type}:stream

Stabilisce una connessione persistente al flusso Firehose, tramite la quale verranno recapitati i dati in tempo reale.

<div id="request-specifications">
  #### Specifiche della richiesta
</div>

|     |     |
| :--- | :--- |
| **Metodo della richiesta** | HTTP GET |
| **Tipo di connessione** | Keep-Alive  <br />  <br />Questo va specificato nell’header della richiesta. |
| **URL** | Indicato nella pagina di aiuto dell’API del flusso nella tua dashboard, con la seguente struttura:  <br />  <br />Decahose:<br /><br />[https://gnip-stream.x.com/stream/sample10/accounts/:account\_name/publishers/twitter/:stream\_label.json?partition=1](https://gnip-stream.x.com/stream/sample10/accounts/:account_name/publishers/twitter/:stream_label.json?partition=1) |
| **Partition (obbligatorio)** | `partition=\{#}` - Il partizionamento è ora obbligatorio per consumare l’intero flusso. È necessario connettersi al flusso specificando il parametro di partizione. Di seguito il numero di partizioni per flusso:<br /><br />\* Decahose: 2 partizioni |
| **Compressione** | Gzip. Per connetterti al flusso utilizzando la compressione Gzip, invia un header Accept-Encoding nella richiesta di connessione. L’header dovrebbe essere il seguente:  <br />  <br />Accept-Encoding: gzip |
| **Codifica dei caratteri** | UTF-8 |
| **Formato della risposta** | JSON. L’header della richiesta dovrebbe specificare il formato JSON per la risposta. |
| **Rate limit** | 10 richieste ogni 60 secondi. |
| **Parametro Backfill** | Se hai acquistato un flusso con Backfill abilitato, aggiungi il parametro "backfillMinutes" nella richiesta GET per abilitarlo. |
| **Read timeout** | Imposta un timeout di lettura sul client e assicurati che sia superiore a 30 secondi. |
| **Supporto per le modifiche ai Tweet** | Tutti gli oggetti Tweet includeranno metadati di modifica che descrivono la cronologia delle modifiche del Tweet. Consulta la pagina dei fondamenti ["Modifica dei Tweet"](/it/x-api/enterprise-gnip-2.0/fundamentals/edit-tweets) per maggiori dettagli. |

<div id="responses">
  #### Risposte
</div>

Le seguenti risposte possono essere restituite dall’API per queste richieste. La maggior parte dei codici di errore è accompagnata da una stringa con dettagli aggiuntivi nel body. Per risposte diverse da 200, i client dovrebbero tentare di riconnettersi.

| Stato | Testo | Descrizione |
| :--- | :--- | :--- |
| 200 | Successo | La connessione è stata aperta correttamente e le nuove attività verranno inviate man mano che arrivano. |
| 401 | Non autorizzato | L’autenticazione HTTP non è riuscita a causa di credenziali non valide. Accedi a console.gnip.com con le tue credenziali per verificare che le stia utilizzando correttamente nella richiesta. |
| 406 | Non accettabile | In genere si verifica quando il client non include correttamente le intestazioni per accettare la codifica gzip dallo stream, ma può verificarsi anche in altre circostanze.  <br />  <br />Contiene un messaggio JSON simile a: "Questa connessione richiede la compressione. Per abilitare la compressione, invia un’intestazione 'Accept-Encoding: gzip' nella richiesta ed effettua la decompressione dello stream lato client durante la lettura." |
| 429 | Limite di frequenza superato | L’app ha superato il limite per le richieste di connessione. |
| 503 | Servizio non disponibile | Problema lato server di Twitter. Riconnettiti usando un backoff esponenziale. Se non è stato pubblicato alcun avviso su questo problema sulla [X API Status Page](https://api.twitterstat.us/), contatta l’assistenza o l’emergenza se non riesci a connetterti dopo 10 minuti. |

<div id="example-curl-request">
  #### Esempio di richiesta curl
</div>

La seguente richiesta di esempio viene eseguita con cURL da riga di comando. Tieni presente, tuttavia, che tali richieste possono anche essere inviate usando il linguaggio di programmazione che preferisci:

```
curl --compressed -v -uexample@customer.com "https://gnip-stream.x.com/stream/firehose/accounts/:account\_name/publishers/twitter/:stream\_label.json?partition={#}"
```

<div id="replay-api">
  #### API Replay
</div>

L’API Replay è un importante complemento ai flussi Volume in tempo reale. Replay è uno strumento di ripristino dati che offre accesso in streaming a una finestra mobile dei dati storici recenti di X.