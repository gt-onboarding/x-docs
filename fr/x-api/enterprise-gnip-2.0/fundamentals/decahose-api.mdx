---
title: API Decahose
---

<Note>
  Ce point de terminaison a été mis à jour pour inclure les métadonnées d’édition de posts. Pour en savoir plus sur ces métadonnées, consultez la page Fondamentaux ["Modifier des posts"](/fr/x-api/enterprise-gnip-2.0/fundamentals/edit-tweets). 
</Note>

<div id="decahose-stream">
  ### Flux Decahose
</div>

[Enterprise](https://developer.x.com/en/products/x-api/enterprise)

_Ceci est une API Enterprise disponible uniquement dans nos niveaux d’accès gérés. Pour utiliser cette API, vous devez d’abord configurer un compte avec notre équipe commerciale Enterprise. [En savoir plus](https://developer.x.com/en/products/x-api/enterprise)_

Le Decahose fournit, via une connexion de streaming, un échantillon aléatoire de 10 % du Firehose X en temps réel. Cela est rendu possible par un algorithme d’échantillonnage en temps réel qui sélectionne aléatoirement les données tout en garantissant une livraison à faible latence conforme aux attentes, au fur et à mesure que X les envoie dans le firehose.

Vous trouverez ci-dessous certaines des fonctionnalités disponibles avec Decahose :

- **URL étendues et enrichies :** - déroule entièrement les URL raccourcies et fournit des métadonnées supplémentaires (titre et description de la page)
- **Partitionnement du flux** - 2 partitions, chacune contenant 50 % du volume du flux Decahose
- **Fiabilité améliorée** - diversité géographique des systèmes back-end

Remarque : ces données sont livrées en vrac et ne prennent pas en charge de filtrage supplémentaire (p. ex. des mots-clés).

`ENTERPRISE`

<div id="streaming-likes">
  ### Diffusion des mentions J’aime
</div>

_Ceci est une API Entreprise disponible uniquement dans le cadre de nos niveaux d’accès gérés. Pour utiliser cette API, vous devez d’abord établir un compte avec notre équipe commerciale dédiée aux entreprises. [En savoir plus](https://developer.x.com/en/products/x-api/enterprise)_

Les mentions J’aime fournissent une visibilité sur qui aime des Posts et des décomptes précis des J’aime. Le Firehose et le Decahose de Gnip peuvent diffuser les mentions J’aime publiques liées aux Posts livrés via Gnip. Cela offre des mesures d’engagement public et d’audience en temps réel associées à un Post.
 

**Premiers pas avec les mentions J’aime**

Au moment de consommer des données de mentions J’aime, sachez que :

- Les mentions J’aime sont diffusées via un flux distinct et indépendant
- Historiquement, les mentions J’aime étaient appelées « Favoris ». La charge utile au format natif enrichi conserve cette nomenclature
- Les flux incluent uniquement les mentions J’aime publiques
  - Public signifie que l’utilisateur qui aime, le créateur du Post et le Post sont tous publics sur la plateforme
- Les mentions J’aime sont très similaires aux Retweets et constituent un signal public d’engagement
- Les éléments de la charge utile incluent :
  - Objet Post d’origine
  - Objet Acteur ayant créé le Post d’origine
  - Objet Acteur ayant effectué l’action J’aime
- Seul le contenu d’origine peut être aimé
  - Les Retweets ne peuvent pas être aimés. Une mention J’aime sur un Retweet est appliquée au Post d’origine
  - Les Tweets cités _peuvent_ être aimés
- Les activités J’aime incluent les enrichissements Gnip applicables (lorsqu’ils sont achetés/appliqués)
- Produits / fonctionnalités pris en charge
  - Les flux de mentions J’aime prennent en charge le Backfill (lorsqu’il est acheté/appliqué)
  - Il n’y a pas de prise en charge du Replay pour les flux de mentions J’aime
  - Il n’y a pas de prise en charge de la recherche ni de l’historique pour les mentions J’aime
  - Il n’existe aucun projet immédiat visant à ajouter la prise en charge des mentions J’aime à PowerTrack

**Decahose**

- Pour l’échantillon de 10 % des Posts diffusés dans le Decahose, le flux inclut 100 % des mentions J’aime publiques applicables
- **Partitions :** 2
- **Structure d’URL**
  - https://gnip-stream.x.com/stream/sample10-likes/accounts/\<accountName>/publishers/twitter/\<streamLabel>.json?partition=1

**Charge utile au format natif enrichi**

```json
{
   "id":"43560406e0ad9f68374445f5f30c33fc",
   "created_at":"Thu Dec 01 22:27:39 +0000 2016",
   "timestamp_ms":1480631259353,
   "favorited_status":{
      "created_at":"Thu Dec 01 22:27:16 +0000 2016",
      "id":804451830033948672,
      "id_str":"804451830033948672",
      "text":"@kafammheppduman",
      "source":"\u003ca href=\"http:\/\/x.com\/download\/android\" rel=\"nofollow\"\u003eX pour Android\u003c\/a\u003e"
      "truncated":false,
      "in_reply_to_status_id":803694205163814912,
      "in_reply_to_status_id_str":"803694205163814912",
      "in_reply_to_user_id":2855759795,
      "in_reply_to_user_id_str":"2855759795",
      "in_reply_to_screen_name":"kafammheppduman",
      "user":{
         "id":2855759795,
         "id_str":"2855759795",
         "name":"delirdim kanka",
         "screen_name":"kafammheppduman",
         "location":"sanane",
         "url":"http:\/\/instagram.com\/kafammheppduman",
         "description":"Manit @GalatasaraySk \ud83d\udc9e",
         "translator_type":"none",
         "protected":false,
         "verified":false,
         "followers_count":3702,
         "friends_count":607,
         "listed_count":1,
         "favourites_count":113338,
         "statuses_count":389,
         "created_at":"Sat Nov 01 22:38:25 +0000 2014",
         "utc_offset":null,
         "time_zone":null,
         "geo_enabled":true,
         "lang":"tr",
         "contributors_enabled":false,
         "is_translator":false,
         "profile_background_color":"C0DEED",
         "profile_background_image_url":"",
         "profile_background_image_url_https":"",
         "profile_background_tile":false,
         "profile_link_color":"1DA1F2",
         "profile_sidebar_border_color":"C0DEED",
         "profile_sidebar_fill_color":"DDEEF6",
         "profile_text_color":"333333",
         "profile_use_background_image":true,
       "Profile_image_url": "http:\/\/pbs.twimg.com\/profile_images\/804421763945861121\/v3bp9pnq_normal.jpg",
         "Profile_image_url_https": "https:\/\/pbs.twimg.com\/profile_images\/804421763945861121\/v3bp9pnq_normal.jpg",
         "profile_banner_url":"https:\/\/pbs.twimg.com\/profile_banners\/2855759795\/1480630085",
         "default_profile":true,
         "default_profile_image":false,
         "following":null,
         "follow_request_sent":null,
         "notifications":null
      },
      "geo":null,
      "coordinates":null,
      "place":null,
      "contributors":null,
      "is_quote_status":false,
      "retweet_count":0,
      "favorite_count":0,
      "entities":{
         "hashtags":[],
         "urls":[],
         "user_mentions":[
            {
               "screen_name":"kafammheppduman",
               "name":"delirdim kanka",
               "id":2855759795,
               "id_str":"2855759795",
               "indices":[
                  0,
                  16
               ]
            }
         ],
         "symbols":[]
      },
      "favorited":false,
      "retweeted":false,
      "filter_level":"low",
      "lang":"und"
   },
   "user":{
      "id":774146932365070336,
      "id_str":"774146932365070336",
      "name":"Uyuyan Adam",
      "screen_name":"saykoMenn",
      "location":"Tarsus, T\u00fcrkiye",
      "url":"http:\/\/connected2.me\/pmc1i",
      "description":null,
      "translator_type":"none",
      "protected":false,
      "verified":false,
      "followers_count":414,
      "friends_count":393,
      "listed_count":0,
      "favourites_count":9868,
      "statuses_count":370,
      "created_at":"Fri Sep 09 07:26:26 +0000 2016",
      "utc_offset":null,
      "time_zone":null,
      "geo_enabled":false,
      "lang":"tr",
      "contributors_enabled":false,
      "is_translator":false,
      "profile_background_color":"F5F8FA",
      "profile_background_image_url":"",
      "profile_background_image_url_https":"",
      "profile_background_tile":false,
      "profile_link_color":"1DA1F2",
      "profile_sidebar_border_color":"C0DEED",
      "profile_sidebar_fill_color":"DDEEF6",
      "profile_text_color":"333333",
      "profile_use_background_image":true,
      "profile_image_url": "http://pbs.twimg.com/profile_images/802992813424201728/VMzcTL3x_normal.jpg",
      "profile_image_url_https": "https://pbs.twimg.com/profile_images/802992813424201728/VMzcTL3x_normal.jpg",
      "profile_banner_url":"https://pbs.twimg.com/profile_banners/774146932365070336/1480283382",
      "default_profile":true,
      "default_profile_image":false,
      "following":null,
      "follow_request_sent":null,
      "notifications":null
   }
}
```

**Charge utile de suppression de J’aime / « Retirer le J’aime »**

```json
{
   "delete":{
      "favorite":{
         "tweet_id":696615514970279937,
         "tweet_id_str":"696615514970279937",
         "user_id":2510287578,
         "user_id_str":"2510287578"
      },
      "timestamp_ms":"1480437031205"
   }
}
```

<div id="guides">
  ## Guides
</div>

<div id="recovery-and-redundency">
  ### Récupération et redondance
</div>

**Introduction** 

La diffusion en continu de volumes élevés de Posts en temps réel s’accompagne d’un ensemble de bonnes pratiques qui favorisent à la fois la fiabilité et l’intégrité complète des données. Lors de la consommation de données en temps réel, maximiser le temps de connexion est un objectif fondamental. En cas de déconnexion, il est important de la détecter automatiquement et de se reconnecter. Après la reconnexion, il convient d’évaluer s’il existe des périodes à reconstituer. Le composant qui gère ces aspects et consomme les Posts en temps réel n’est qu’une partie d’un système qui implique le réseau, les bases de données, les serveurs et le stockage. Étant donné la complexité de ces systèmes, une autre bonne pratique consiste à disposer de différents environnements de streaming, avec au minimum des flux distincts pour le développement/les tests et la production.

Decahose propose un ensemble de fonctionnalités qui facilitent ces efforts.

1. Pour prendre en charge plusieurs environnements, nous pouvons déployer des [flux supplémentaires](#AdditionalStreams) pour votre compte. Ces flux sont indépendants les uns des autres et disposent d’un stream\_label différent pour les différencier.
2. Pour aider à maintenir la connexion, chaque flux Decahose prend en charge des [connexions redondantes](/fr/x-api/enterprise-gnip-2.0/fundamentals/decahose-api#additional-streams). L’architecture la plus courante consiste à ce qu’un flux ait deux connexions et, côté client, deux consommateurs indépendants — idéalement sur des réseaux différents. Avec cette conception, il peut y avoir de la redondance au niveau des réseaux côté client, des serveurs et des chemins d’accès aux bases de données. Notez qu’une copie complète des données est fournie sur chaque connexion et que le client doit tolérer et gérer les doublons.
3. Un « heartbeat » est envoyé toutes les 10 secondes ; toutefois, avec le flux Decahose, le volume de données est suffisamment élevé pour que même une courte période (par exemple, quelques secondes) sans Posts puisse indiquer un problème de connexion. Par conséquent, un « silence de données » comme l’absence de heartbeat peuvent servir à détecter une déconnexion.

Comme les déconnexions se produiront, le flux Decahose dispose de fonctionnalités dédiées de [récupération](/fr/x-api/enterprise-gnip-2.0/fundamentals/decahose-api#overview) et de [rattrapage](/fr/x-api/enterprise-gnip-2.0/fundamentals/decahose-api#backfill) pour aider à récupérer les données manquantes en raison de déconnexions et d’autres incidents opérationnels.

<div id="additional-streams">
  #### Flux supplémentaires
</div>

Disposer de flux Decahose supplémentaires est une autre façon d’améliorer la fiabilité de votre solution. Chaque flux supplémentaire est entièrement indépendant, avec son propre endpoint. Chaque flux se voit attribuer son propre stream\_label, et cette étiquette, avec votre nom de compte, fait partie de l’URL de ce flux. Voir l’exemple ci-dessous :

https://gnip-stream.x.com/stream/sample10/accounts/:account\_name/publishers/twitter/:stream\_label.json

La convention la plus courante est d’avoir un flux en temps réel dédié à votre système de production, et un flux supplémentaire disponible pour le développement et les tests. Disposer d’un flux de test/développement permet aux clients Decahose de tester les mises à jour de leurs consommateurs côté client. Bien que toute étiquette (unique) puisse être attribuée à un flux, une convention consiste à utiliser « prod » pour le flux de production, et « dev » ou « sandbox » pour un flux de développement supplémentaire.

Le nombre de flux, et leurs étiquettes uniques, est configurable par votre chargé de compte.

**Connexions redondantes**

Une connexion redondante vous permet simplement d’établir plus d’une connexion simultanée au flux de données. Cela apporte de la redondance en vous permettant de vous connecter au même flux avec deux consommateurs distincts, recevant les mêmes données via les deux connexions. Ainsi, votre application dispose d’un basculement à chaud pour diverses situations, par exemple lorsqu’un flux est déconnecté ou lorsque le serveur principal de votre application tombe en panne.

Le nombre de connexions autorisées pour un flux donné est configurable par votre chargé de compte. Pour utiliser une connexion redondante, connectez-vous simplement à la même URL que celle utilisée pour votre connexion principale. Les données de votre flux seront envoyées via les deux connexions, les deux connexions de flux étant représentées sur le tableau de bord du flux.

Notez qu’à des fins de facturation, nous dédupliquons le comptage des activités que vous recevez via plusieurs connexions, de sorte que vous ne soyez facturé qu’une seule fois pour chaque activité unique. Étant donné que Decahose possède deux partitions, voici un exemple illustrant le fonctionnement du comptage des connexions ci-dessous :

Connect to decahose partition=1
Connect to decahose partition=1
Connect to decahose partition=2

La situation ci-dessus donne un total de trois connexions – deux connexions à partition=1 et une connexion à partition=2. Normalement, vous voudriez le même nombre de connexions pour chaque partition ; cet exemple met donc en évidence une situation où la connexion redondante à partition=2 est tombée et où vous souhaitez enquêter davantage.

**Récupération**

#### Vue d’ensemble 

Recovery est un outil de récupération de données (à ne pas utiliser pour la collecte de données primaire) qui offre un accès en streaming à une fenêtre glissante de 5 jours de données historiques récentes sur X. Il doit être utilisé pour récupérer des données lorsque votre application consommatrice manque des données du flux temps réel, que ce soit en raison d’une brève déconnexion ou de tout autre scénario où vous n’avez pas pu ingérer les données en temps réel pendant une période donnée.

#### Utilisation de Recovery 

Avec le flux Recovery, votre application peut envoyer des requêtes qui fonctionnent de la même manière que celles adressées aux flux en temps réel. Cependant, votre application doit spécifier dans l’URL des paramètres indiquant la fenêtre temporelle demandée. Autrement dit, une requête Recovery demande à l’API « publications de l’heure A à l’heure B ». Ces publications sont ensuite transmises via votre connexion de streaming d’une manière qui imite le flux en temps réel, mais à un rythme légèrement plus lent que le temps réel. Voir ci-dessous un exemple :

"https://stream-data-api.x.com/stream/powertrack/accounts/someAccountName/publishers/twitter/powertrack.json?startTime=2023-07-05T17:09:12.070Z"

Les publications sont livrées en commençant par la première (la plus ancienne) minute de la période spécifiée, puis en continuant chronologiquement jusqu’à la dernière minute. À ce moment-là, un message Recovery Request Completed est envoyé via la connexion, puis le serveur ferme la connexion. Si votre requête commence à un moment de la journée où peu ou pas de résultats correspondants se sont produits, il est probable qu’un certain temps s’écoule avant la livraison des premiers résultats ; les données seront transmises lorsque Recovery rencontrera des correspondances dans la portion de l’archive en cours de traitement à ce moment-là. Lorsqu’aucun résultat n’est disponible, le flux continue d’envoyer des retours chariot, ou « battements de cœur », via la connexion pour éviter l’expiration de la session.

Recovery est conçu comme un outil pour récupérer facilement des données manquées à cause de courtes déconnexions, et non pour de très longues périodes comme une journée entière. Si vous devez récupérer des données sur de longues périodes, nous recommandons de scinder les requêtes longues en fenêtres temporelles plus courtes (par ex. deux heures) afin de réduire le risque de déconnexion en cours de requête en raison de la volatilité d’Internet ou d’autres facteurs, et d’offrir une meilleure visibilité sur l’avancement des requêtes longues.

<div id="data-availability">
  #### Disponibilité des données
</div>

Vous pouvez utiliser la fonctionnalité de récupération pour récupérer les données manquées au cours des dernières 24 heures si vous n’êtes pas en mesure de vous reconnecter dans la fenêtre de rattrapage de 5 minutes.

La fonctionnalité de récupération de flux vous permet de bénéficier d’une fenêtre de rattrapage étendue de 24 heures. La récupération vous permet de « récupérer » la période de données manquées. Un flux de récupération est lancé lorsque vous effectuez une requête de connexion en utilisant les paramètres de requête « start\_time » et « end\_time ». Une fois connecté, la récupération retransmettra la période indiquée, puis se déconnectera.  

Vous pouvez effectuer 2 requêtes de récupération simultanées, c’est‑à‑dire « deux tâches de récupération ». Techniquement, la récupération fonctionne de la même manière que le rattrapage, sauf qu’une heure de début et une heure de fin sont définies. Une période de récupération correspond à une seule plage temporelle.

<div id="backfill">
  #### Rétroremplissage
</div>

Pour demander un rétroremplissage, vous devez ajouter le paramètre backfillMinutes=N à votre requête de connexion, où N est le nombre de minutes (1 à 5, nombres entiers uniquement) à rétroremplir au moment de l’établissement de la connexion. Par exemple, si vous êtes déconnecté pendant 90 secondes, vous devez ajouter backfillMinutes=2 à votre requête de connexion. Étant donné que cette requête fournira un rétroremplissage de 2 minutes, y compris pour les 30 secondes précédant votre déconnexion, votre _application consommatrice doit tolérer les doublons_.

Un exemple d’URL de requête de connexion Decahose, demandant un rétroremplissage de 5 minutes vers la partition 1, est :

https://gnip-stream.x.com/stream/sample10/accounts/:account\_name/publishers/twitter/:stream\_label.json?partition=1\&backfillMinutes=5

**REMARQUES :**

- Vous pouvez choisir d’utiliser systématiquement « backfillMinutes=5 » lors de la connexion, puis de gérer les éventuels doublons fournis.

- Si vous êtes déconnecté plus de cinq minutes, vous pouvez récupérer les données à l’aide de Recovery.

**Récupération après déconnexion**

Redémarrer et se remettre d’une déconnexion implique plusieurs étapes :

- Déterminer la durée de la période de déconnexion.
  - 5 minutes ou moins ?
    - Si Backfill est activé pour le flux, préparez la requête de connexion avec le paramètre « backfillMinutes » approprié.
  - Plus de 5 minutes ?
    - Si vous disposez d’un flux Recovery, effectuez une requête Recovery pour la période de déconnexion (idéalement avec votre jeu de règles temps réel actuel, en utilisant l’API Rules si nécessaire).
- Demander une nouvelle connexion.

Lorsque vous rencontrez des déconnexions ou des interruptions, voici des stratégies pour atténuer l’impact et vous rétablir dans ce scénario :

1. **Implémenter le rétroremplissage**
   Le rétroremplissage vous permet de vous reconnecter à partir d’un point antérieur à la déconnexion d’un flux et couvre les déconnexions jusqu’à 5 minutes. Il s’implémente en ajoutant un paramètre à la requête de connexion.

2. **Consommer un flux redondant depuis un autre emplacement**
   Si le flux redondant peut être diffusé dans le même environnement en direct, avec déduplication des données, vous éliminerez le besoin de récupération sauf si le flux normal ET le flux redondant subissent simultanément une interruption ou une déconnexion. Si le flux redondant ne peut pas être diffusé en direct dans l’environnement de production, il peut être écrit dans un magasin de données « d’urgence » séparé. Ainsi, en cas de déconnexions ou d’interruptions sur la connexion de flux principale, votre système disposera de données à utiliser pour compléter votre base principale sur la période où des données manquent.

3. **Implémenter Recovery**
   Lorsque des déconnexions ou des interruptions affectent à la fois le flux principal et le flux redondant, utilisez Decahose Recovery pour récupérer toute donnée manquée. L’API fournit une fenêtre glissante couvrant 5 jours d’archive, et il est préférable de l’utiliser en demandant au plus une heure de cette fenêtre à la fois, puis en la diffusant. Cela se fait en parallèle du flux temps réel. Notez que nous n’avons pas de solution pour récupérer des données Decahose au-delà de la fenêtre de 5 jours fournie par Recovery ; il est donc important d’utiliser un flux redondant pour vous assurer de disposer d’une copie complète des données de votre côté en cas d’interruption significative.

Lorsque vous détectez des volumes de données stockées anormaux —
Façons possibles de détecter des données manquantes alors qu’aucune déconnexion ni interruption ne s’est produite…

1. Compter les Posts entrants
   Votre système doit compter le nombre brut de Posts reçus dès l’entrée de votre application d’ingestion, puis fournir un moyen de comparer ces nombres au nombre de Posts qui parviennent à votre magasin de données final. Toute différence peut être surveillée et alerter votre équipe sur des problèmes entraînant la perte de données après leur réception.

2. Analyser les volumes stockés anormaux
   Vous pouvez également analyser les volumes de données stockées dans votre base de données finale pour rechercher des baisses anormales. Cela peut également indiquer des problèmes, même s’il existe vraisemblablement des circonstances où des baisses de volume sont normales (par exemple, si la plateforme X est indisponible et que les utilisateurs ne peuvent pas créer de Posts pendant un certain temps).

<div id="api-reference">
  ## Référence de l’API
</div>

<div id="decahose-stream">
  ### Flux Decahose
</div>

Aller à cette section

[Méthodes](/fr/x-api/enterprise-gnip-2.0/fundamentals/decahose-api#methods)

[Authentification](/fr/x-api/enterprise-gnip-2.0/fundamentals/decahose-api#authentication)

[GET /\{stream-type}/:stream](/fr/x-api/enterprise-gnip-2.0/fundamentals/decahose-api#get-stream-type-stream)

[API de relecture](/fr/x-api/enterprise-gnip-2.0/fundamentals/decahose-api#replay-api)

<div id="methods">
  #### Méthodes
</div>

| Méthode | Description |
| :--- | :--- |
| [GET /\{stream-type}/:stream](#Stream) | Connexion au flux de données |

<div id="authentication">
  #### Authentification[](#authentication- "Permalink to this headline")
</div>

Toutes les requêtes vers les API Volume Stream doivent utiliser l’authentification HTTP Basic, basée sur une adresse e‑mail et un mot de passe valides utilisés pour vous connecter à votre compte sur console.gnip.com. Les identifiants doivent être transmis dans l’en-tête Authorization pour chaque requête. Vérifiez donc que votre client ajoute l’en-tête HTTP "Authorization: Basic" (avec identifiants encodés via HTTPS) à toutes les requêtes API.

#### GET \{stream-type}:stream

Établit une connexion persistante au flux Firehose, via laquelle les données en temps réel seront transmises.

<div id="request-specifications">
  #### Spécifications de la requête
</div>

|     |     |
| :--- | :--- |
| **Méthode de requête** | HTTP GET |
| **Type de connexion** | Keep-Alive  <br />  <br />Cela doit être indiqué dans l’en-tête de la requête. |
| **URL** | Disponible sur la page d’aide de l’API du flux dans votre tableau de bord, selon la structure suivante :  <br />  <br />Decahose :<br /><br />[https://gnip-stream.x.com/stream/sample10/accounts/:account\_name/publishers/twitter/:stream\_label.json?partition=1](https://gnip-stream.x.com/stream/sample10/accounts/:account_name/publishers/twitter/:stream_label.json?partition=1) |
| **Partition (obligatoire)** | `partition=\{#}` - La partition est désormais requise pour consommer l’intégralité du flux. Vous devez vous connecter au flux avec le paramètre de partition spécifié. Ci-dessous, le nombre de partitions par flux :<br /><br />\* Decahose : 2 partitions |
| **Compression** | Gzip. Pour vous connecter au flux avec la compression Gzip, envoyez simplement un en-tête Accept-Encoding dans la requête de connexion. L’en-tête doit être le suivant :  <br />  <br />Accept-Encoding: gzip |
| **Encodage des caractères** | UTF-8 |
| **Format de réponse** | JSON. L’en-tête de votre requête doit spécifier le format JSON pour la réponse. |
| **Limite de débit** | 10 requêtes toutes les 60 secondes. |
| **Paramètre de rattrapage** | Si vous avez acheté un flux avec Backfill activé, vous devez ajouter le paramètre « backfillMinutes » à la requête GET pour l’activer. |
| **Délai d’expiration de lecture** | Définissez un délai d’expiration de lecture sur votre client et assurez-vous qu’il est supérieur à 30 secondes. |
| **Prise en charge des modifications de Tweet** | Tous les objets Tweet incluront des métadonnées d’édition décrivant l’historique des modifications du Tweet. Consultez la page des fondamentaux « Modifier des Tweets » ([/x-api/enterprise-gnip-2.0/fundamentals/edit-tweets](/fr/x-api/enterprise-gnip-2.0/fundamentals/edit-tweets)) pour plus de détails. |

<div id="responses">
  #### Réponses
</div>

Les réponses suivantes peuvent être renvoyées par l’API pour ces requêtes. La plupart des codes d’erreur sont renvoyés avec une chaîne contenant des détails supplémentaires dans le corps. Pour les réponses non-200, les clients doivent tenter de se reconnecter.

| Statut | Texte | Description |
| :--- | :--- | :--- |
| 200 | Réussite | La connexion a été ouverte avec succès et de nouvelles activités seront envoyées au fur et à mesure de leur arrivée. |
| 401 | Non autorisé | L’authentification HTTP a échoué en raison d’identifiants invalides. Connectez-vous à console.gnip.com avec vos identifiants pour vérifier que vous les utilisez correctement dans votre requête. |
| 406 | Non acceptable | En général, cela se produit lorsque votre client n’inclut pas correctement les en-têtes indiquant l’acceptation de l’encodage gzip pour le flux, mais cela peut également se produire dans d’autres circonstances.  <br />  <br />Contiendra un message JSON semblable à « Cette connexion nécessite une compression. Pour activer la compression, envoyez un en-tête “Accept-Encoding: gzip” dans votre requête et préparez-vous à décompresser le flux lors de sa lecture côté client. » |
| 429 | Limite de débit atteinte | Votre application a dépassé la limite de demandes de connexion. |
| 503 | Service indisponible | Problème côté serveur X. Reconnectez-vous en utilisant un backoff exponentiel. Si aucun avis concernant ce problème n’a été publié sur la [page d’état de l’API X](https://api.twitterstat.us/), contactez l’assistance ou le support d’urgence si vous ne parvenez pas à vous connecter après 10 minutes. |

<div id="example-curl-request">
  #### Exemple de requête curl
</div>

L’exemple de requête ci-dessous utilise cURL en ligne de commande. Notez toutefois que ces requêtes peuvent aussi être envoyées dans le langage de programmation de votre choix :

```
curl --compressed -v -uexample@customer.com "https://gnip-stream.x.com/stream/firehose/accounts/:account\_name/publishers/twitter/:stream\_label.json?partition={#}"
```

<div id="replay-api">
  #### API Replay
</div>

L’API Replay est un complément important aux flux de volume en temps réel. Replay est un outil de récupération de données qui fournit un accès en continu à une fenêtre glissante des données historiques récentes de X.